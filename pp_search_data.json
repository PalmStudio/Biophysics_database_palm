[{"url":"02-climate/climate_notebook/","title":"Climate data","tags":["climate"],"text":" A Pluto.jl notebook v0.19.42 frontmatter title \"Climate data\" layout \"layout.jlhtml\" description \"Climate data of both chambers in the Ecotron.\" tags \"climate\" using Markdown using InteractiveUtils begin using CSV using DataFrames using ZipFile using Dates using Statistics using PlutoUI end md\"\"\" Chamber climate Two chambers were used for the experiment in the Ecotron the microcosm 3 mic3 and microcosm 4 mic4 . The climate inside the two chambers was finely controlled during the whole experiment. `mic4` was used to store the plants following the reference scenario, and `mic3` for measuring response of one plant to specific conditions. The data was exported regularly, resulting in several files for each chamber. The aim of this notebook is to make one single file for each chamber. Imports Loading the dependencies \"\"\" md\"\"\" Read the data Read the data from the zip archive, without uncompressing all files \"\"\" begin r ZipFile.Reader \".. 00 data climate climate.zip\" mic4 files mic3 files for f in r.files startswith f.name, \"Mic4\" && push mic4 files, CSV.read f, DataFrame startswith f.name, \"Mic3\" && push mic3 files, CSV.read f, DataFrame end close r mic3 vcat mic3 files... mic4 vcat mic4 files... select mic3, Not Column1 select mic4, Not Column1 nothing end md\"\"\" Data cleaning \"\"\" md\"\"\" Some data is duplicated in the files they are overlapping , so we need to make the rows unique in the dataframes. We also need to rename the variables into more sensible names, adapted to programming tasks, i.e. not using empty spaces, or unusal characters. \"\"\" mic3 df select unique mic3 , \"DateTime\" x DateTime. x, dateformat\"yyy mm dd HH MM SS\" \"DateTime\", \"consigne T\\xb0C\" Ta instruction, \"mesure T\\xb0C\" Ta measurement, \"consigne HR\" Rh instruction, \"mesure HR\" Rh measurement, \"consigne Rayo\" R instruction, \"mesure Rayo\" R measurement, \"mesures CO2 \" CO2 ppm, \"mesure debit CO2\" CO2 flux, \"Mic\" mic4 df select unique mic4 , \"DateTime\" x DateTime. x, dateformat\"yyy mm dd HH MM SS\" \"DateTime\", \"consigne T\\xb0C\" Ta instruction, \"mesure T\\xb0C\" Ta measurement, \"consigne HR\" Rh instruction, \"mesure HR\" Rh measurement, \"consigne Rayo\" R instruction, \"mesure Rayo\" R measurement, \"mesures CO2 \" CO2 ppm, \"Mic\" md\"\"\" 5 minute time step Mic3 The climate files are at a 30s time step, but the CO2 fluxes are measured for 5 minutes every 10 minutes 5min input 5min output , so we need the climate data integrated at 5min time step when there is a measurement of CO2 flux. First, we add a new column for the CO2 instructions in the chamber, which will be less noisy than the measurement `CO2 ppm` , because it will be defined more as a factorial variable. To do so, we use the CO2 flux because it is more reliable than the CO2 concentration measurement. \"\"\" md\"\"\" Second, we import the data of the CO2 fluxes measurements in the chamber, which gives us the start and end time of each measurement session. The input CO2 is measured for 5 minutes, and then the output is measured for 5 minutes. The input CO2 correspond to the instruction in input to get the chamber to a given CO2 concentration in the air, and the output CO2 is the air from the chamber, that is measured to compute the CO2 fluxes from the plant i.e. respiration and photosynthesis . \"\"\" needed period df let df CSV.read \".. 00 data picarro flux data mean flux.csv\", DataFrame transform df , MPV1 time x DateTime. x, dateformat\"dd mm yyy HH MM\" MPV1 time, MPV2 time x DateTime. x, dateformat\"dd mm yyy HH MM\" MPV2 time transform df , MPV1 time x x . Second 150 DateTime start input, MPV1 time x x . Second 150 DateTime end input, MPV2 time x x . Second 150 DateTime start output, MPV2 time x x . Second 150 DateTime end output df end md\"\"\" note We remove add 150 seconds to the DateTime because it is given as the average time between a valve opening and closing, and we want the time of valve opening and closing. \"\"\" md\"\"\" Now that we have the time windows of measurement, we can use it to compute the average conditions inside these windows. We make two different tables, on that averages only the conditions inside a measurement session just for the 5 min of CO2 output , and another that uses the 10 minute average, starting with the input CO2 and then the output CO2 for each 10 minute time step. \"\"\" md\"\"\" Saving Lastly, we write the new dataframes to disk \"\"\" CSV.write \"climate mic3.csv\", mic3 df CSV.write \"climate mic4.csv\", mic4 df md\"\"\" References \"\"\" \"\"\" is change x Looks when there is a change in the sequence of values. Returns a vector of string, with the value \"no change\" if the current value is the same as the previous one, or \"change\" if it is different. Examples ```julia is change 1,1,1,2,2,2 ``` \"\"\" function is change x change fill \"no change\", length x for i in eachindex change if i 1 && x i x i 1 change i \"change\" end end return change end mic3 2 let df transform mic3 df, CO2 flux ByRow x begin if 30 x 45 return 400.0 elseif 45 x 55 return 600.0 elseif x 55 return 800.0 else return 0.0 end end CO2 instruction, transform df , CO2 instruction is change CO2 change, df end mic3 5min let mic3 copy mic3 2 mic3 .DateTime start Vector Union DateTime,Missing undef, nrow mic3 mic3 .DateTime end Vector Union DateTime,Missing undef, nrow mic3 for row in eachrow needed period df timestamps within findall row.DateTime start output . mic3 .DateTime . row.DateTime end output if length timestamps within 0 mic3 .DateTime start timestamps within . row.DateTime start output mic3 .DateTime end timestamps within . row.DateTime end output end end filter x ismissing x.DateTime start , mic3 mic3 c combine groupby mic3 , DateTime start , DateTime end unique DateTime end, names mic3 , Number . mean . names mic3 , Number , CO2 change x any x . \"change\" ? \"change\" \"no change\" CO2 change mic3 c end CSV.write \"climate mic3 5min.csv\", mic3 5min mic3 10min let mic3 copy mic3 2 mic3 .DateTime start Vector Union DateTime,Missing undef, nrow mic3 mic3 .DateTime end Vector Union DateTime,Missing undef, nrow mic3 nrows df nrow needed period df for row in eachrow needed period df timestamps within findall row.DateTime start input . mic3 .DateTime . row.DateTime end output if length timestamps within 0 mic3 .DateTime start timestamps within . row.DateTime start input mic3 .DateTime end timestamps within . row.DateTime end output end end filter x ismissing x.DateTime start , mic3 mic3 c combine groupby mic3 , DateTime start , DateTime end unique DateTime end, names mic3 , Number . mean . names mic3 , Number , CO2 change x any x . \"change\" ? \"change\" \"no change\" CO2 change mic3 c end CSV.write \"climate mic3 10min.csv\", mic3 10min TableOfContents title \"üìö Table of Contents\" "},{"url":"03-time-synchronization/time_synchronization_notebook/","title":"Time synchronization","tags":["timesync"],"text":" A Pluto.jl notebook v0.19.42 frontmatter title \"Time synchronization\" layout \"layout.jlhtml\" tags \"timesync\" description \"Time synchronization of the different sensors and equipments used in the experiment.\" using Markdown using InteractiveUtils begin using CSV, DataFrames using Dates using Statistics using CairoMakie using AlgebraOfGraphics using PlutoUI end md\"\"\" Time synchronization Introduction The different sensors and equipments used in the experiment can deviate from each other for time. This is a problem when we want to merge all measurements into the same database, and compare them alongside. The equipments include the CO2 fluxes, should be at UTC the scale data logged differently along the experiment the thermal camera Method The equipment from Ecotron are all in UTC and synchronized, this include the CO2 fluxes and the data about the door opening of the chamber. Thermal camera Then, we can use the timestamps of the door opening closing to calibrate the thermal images, as we also can see when the door is open closed from the images itself. This method should have a ~1 minute error at maximum, as the camera was triggered every minute. Of course some data points will not be matched when the door was opened and closed very briefly, i.e. between two images. But the applications of this dataset are at the lowest at a 5 10 minute time step because of the method for the measurement of the CO2 fluxes, so a 1 minute error at maximum is reasonable. Precision scale Similarly, the data from the precision scale can be checked and eventually corrected using the rapid change in weight when adding or removing a plant from it, because we opened the door of the chamber to do so, so we can get the true timestamp from the database of opening closing the door. We can also check with the images from the thermal camera. The precision scale was used to measure the plant transpiration from the weight of the potted plants. The total weight pot and plant was continuously measured during the experiment with the connected precision scale. The pot and soil were isolated using a plastic bag, so any change in the pot weight was due to the plant transpiration the saturation inside the bag . There are five phases of measurement due to changes in the measurement setup phase 0, from 09 03 2021 to 10 03 2021, logged in the file `Weights 1.txt`. In this phase we used a regular computer with a script that read the data from the scale 1000C 3000D for one minute, and logged its average onto the computer. The DateTime should be close to UTC 1. phase 1, from 2021 03 10T15 08 23 to 2021 03 15T14 49 06, file `weightsPhase1.txt`. We changed computers to use one from the Ecotron, which should be near UTC 4min. phase 2, from 2021 03 15T15 46 13 to 2021 03 27T01 19 27, file `weightsPhase2.txt`. In this measurement phase, we changed the script to log the data every second, without any averaging as we decided it is better to log the raw data and make the average afterward. The DateTime lag was fixed, so it should be in UTC. These data end the day before day time change. Data is lost for the weekend after 2021 03 27T01 19 27 because the weight of the plant was above the maximum capacity of the scale. phase 3, from 2021 03 30T09 45 01 to 2021 04 08T07 03 59, file `weightsPhase3.txt`. This phase is the same as phase 3, there is just a data gap because we were investigating why data logging was not working anymore we didn't see any error on the scale . phase 4, from 2021 04 07T10 46 19 to 2021 05 02T06 49 33, file `weightsPhase4.txt`. We received the new precision scale XB3200C that we just bought we borrowed the first one . So in this phase we changed the scale, and also isntalled a Raspberry Pi to log the data. The Raspberry Pi is connected to the scale via USB, and the data is logged every second. The DateTime appears to have a lag of 1 day, 47 minutes and 12 seconds compared to UTC Raspberry 2021 04 12T13 02 43 Thermal camera 20210413 144827 R.jpg, with a delay of 3512s, so 2021 04 13T13 49 55 UTC Importing the dependencies \"\"\" md\"\"\" Importing the data The method presented above was applyied manually, and the resulting data was logged into this CSV file \"\"\" df let data CSV.read \"match scale camera time.csv\", DataFrame data.thermal camera DateTime. data.thermal camera, dateformat\"yyyymmdd HHMMSS R\" data.door opening ismissing i ? missing DateTime i, dateformat\"yyyy mm dd HH MM SS\" for i in data.door opening data end md\"\"\" Thermal camera \"\"\" md\"\"\" Build a dataframe with only the data for the thermal camera \"\"\" df thermal select dropmissing df, door opening, thermal camera , door opening, thermal camera, door opening, thermal camera ByRow x, y ismissing x || ismissing y ? missing canonicalize x y error, door opening, thermal camera x, y x y error ms, md\"\"\" Plotting as is Matching the door opening time and thermal camera time as is shows no error at the time scale of the day. \"\"\" data df thermal mapping door opening \"Door opening UTC \", door opening \"Thermal camera time\" visual Lines, color grey, linestyle dash data df thermal mapping door opening \"Door opening UTC \", thermal camera \"Thermal camera time\" | draw md\"\"\" Figure 1. Timestamp of the thermal camera images y compared to the time registered with the closest observed door opening UTC . \"\"\" md\"\"\" By hour But looking at the data on an hourly basis shows a systematic delay in the time registered with the camera. \"\"\" data df thermal mapping door opening x Time x \"Door opening UTC \", door opening x Time x \"Thermal camera\", visual Lines, color grey, linestyle dash data df thermal mapping door opening x Time x \"Door opening UTC \", thermal camera x Time x \"Thermal camera\" visual Scatter | draw md\"\"\" Figure 2. Hour of the thermal camera images y compared to the hour registered with the closest observed door opening UTC . \"\"\" md\"\"\" Correction A correction in the timestamp is then needed. The mean error of the thermal camera timestamps are \"\"\" delay camera Second round mean i.value for i in skipmissing df thermal.error ms 1e 3, digits 0 md\"\"\" We can now add the corrected data to the dataframe \"\"\" df thermal cor transform df thermal, thermal camera x x . delay camera thermal camera cor delay camera md\"\"\" And plot the corrected timestamps in comparison with the previous ones \"\"\" data df thermal cor mapping door opening x Time x \"Door opening UTC \", door opening x Time x \"Thermal camera\", visual Lines, color grey, linestyle dash data df thermal cor mapping door opening x Time x \"Door opening UTC \", thermal camera, thermal camera cor . x Time x . \"Thermal camera\", color dims 1 renamer \"Original\", \"Corrected\" \"Camera\" visual Scatter | draw md\"\"\" Figure 3. Comparison between the original hour of the thermal camera images y and the corrected one, with the closest observed door opening UTC . \"\"\" md\"\"\" The proposed correction seems adequate. \"\"\" md\"\"\" Precision scale \"\"\" df scale select dropmissing df, scale, door opening , phase, scale, door opening, thermal camera, scale, thermal camera ByRow x, y ismissing y ? missing x y error camera, scale, door opening x, y x y error door, md\"\"\" Plotting the error as is The figure below shows that measurements in the phase 4 had a lag that was on the time scale of a day. \"\"\" data df scale mapping door opening \"Door opening UTC \", door opening \"Scale time\" visual Lines, color grey, linestyle dash data df scale mapping door opening \"Door opening UTC \", scale \"Scale time\", color phase | draw md\"\"\" Figure 4. Timestamp of a radical change in the scale data logging y, e.g. from 2300 to 0.1 compared to the time registered with the closest observed door opening UTC . \"\"\" md\"\"\" Looking at the difference between the logged hours, we can see that all phases are close to UTC, except for phase 4 that also have a lag at this time scale. \"\"\" data df scale mapping door opening x Time x \"Door opening UTC \", door opening x Time x \"Scale time\", visual Lines, color grey, linestyle dash data df scale mapping door opening x Time x \"Door opening UTC \", scale, scale cor . x Time x . \"Scale time\", color dims 1 renamer \"Original\", \"Corrected\" \"Camera\" scale x Time x \"Scale time\", color phase visual Scatter | draw md\"\"\" Figure 5. Hour of a radical change in the scale data logging y, e.g. from 2300 to 0.1 compared to the hour registered with the closest observed door opening UTC . \"\"\" md\"\"\" Correction \"\"\" md\"\"\" Computing the average error between the two timestamps shows indeed that the three first phases had an error around 3 4 minutes, but that the fourth phase had an error of more than a day \"\"\" delay scale let df combine groupby df scale, phase , error door x Second round mean abs i.value for i in x 1e 3, digits 0 error scale, transform df , error scale x canonicalize. x error scale canon df end df scale cor transform leftjoin df scale, delay scale, on phase , scale, error scale x, y x . y scale cor data df scale cor mapping door opening \"Door opening UTC \", door opening \"Scale time\", visual Lines, color grey, linestyle dash data df scale cor mapping door opening \"Door opening UTC \", scale, scale cor . \"Scale time\", color dims 1 renamer \"Original\", \"Corrected\" \"Camera\" visual Scatter | draw md\"\"\" Figure 6. Original timestamp of a radical change in the scale data logging y, e.g. from 2300 to 0.1 compared to its correction, with a the time registered with the closest observed door opening UTC . \"\"\" data df scale cor mapping door opening x Time x \"Door opening UTC \", door opening x Time x \"Scale time\", visual Lines, color grey, linestyle dash data df scale cor mapping door opening x Time x \"Door opening UTC \", scale, scale cor . x Time x . \"Scale time\", color dims 1 renamer \"Original\", \"Corrected\" \"Camera\" visual Scatter | draw md\"\"\" Figure 7. Orignial hour of a radical change in the scale data logging y, e.g. from 2300 to 0.1 compared to its correction, with the hour registered with the closest observed door opening UTC . \"\"\" md\"\"\" Saving \"\"\" md\"\"\" We can now write the output computation to disk to be able to use it elsewhere \"\"\" df write vcat select delay scale, phase x \"scale\" type, phase, error scale ByRow x Second x .value delay seconds , DataFrame type \"thermal camera\", phase \"all\", delay seconds Second delay camera .value CSV.write \"time synchronization.csv\", df write TableOfContents title \"üìö Table of Contents\" "},{"url":"04-CO2/CO2_notebook/","title":"CO2 fluxes data","tags":["co2"],"text":" A Pluto.jl notebook v0.19.42 frontmatter title \"CO2 fluxes data\" layout \"layout.jlhtml\" description \"Picaro measurements of the CO2 fluxes in the Ecotron chambers.\" tags \"co2\" using Markdown using InteractiveUtils This Pluto notebook uses bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of bind gives bound variables a default value instead of an error . macro bind def, element quote local iv try Base.loaded modules Base.PkgId Base.UUID \"6e696c72 6542 2067 7265 42206c756150\" , \"AbstractPlutoDingetjes\" .Bonds.initial value catch b missing end local el esc element global esc def Core.applicable Base.get, el ? Base.get el iv el el end end begin using CSV, DataFrames using Dates using CairoMakie using AlgebraOfGraphics using PlutoUI end md\"\"\" CO2 fluxes CO2 fluxes were measured at the chamber scale using a Picarro. The Microcosms platform from the Ecotron includes 13 identical and independent growth chambers. These chambers have a volume of 1.5 m¬≥ with a base area of 1 m¬≤. The chambers allows for finely controling the radiation in the visible spectrum with four LED lamps, and the climatic conditions, including the temperature 5 50¬±0.5¬∞C , relative humidity 20 90¬±3% and CO2 concentration 10 2000ppm . In this experiment, we used two microcosms, one for storage `mic4` and one for measuring `mic3` the plant response to climatic and radiative conditions scenarii. The CO2 flux of the plant in `mic3` was measured for each scenario by 10 minutes time steps measuring the input CO2 concentration to the chamber for 5 minutes, and then the output CO2 concentration for 5 minutes. The CO2 fluxes are noisy due to several factors the conditions change rapidly and are not controled anymore when the door of the chamber is opened, and it can take a bit of time to recover the instruction in teh controled conditions the conditions are not at equilibrium in the transition period between two CO2 scenarios, e.g. from 400 ppm to 600 ppm. \"\"\" md\"\"\" Imports \"\"\" md\"\"\" Data \"\"\" md\"\"\" CO2 fluxes \"\"\" CO2 flux let df CSV.read \".. 00 data picarro flux data mean flux.csv\", DataFrame Some measurements are repeated unique df , MPV1 time transform df , MPV1 time x DateTime. x, dateformat\"dd mm yyy HH MM\" MPV1 time, MPV2 time x DateTime. x, dateformat\"dd mm yyy HH MM\" MPV2 time transform df , MPV1 time x x . Second 150 DateTime start input, MPV1 time x x . Second 150 DateTime end input, MPV2 time x x . Second 150 DateTime start output, MPV2 time x x . Second 150 DateTime end output Some 10 min measurements are not 10 min... for row in 1 nrow df 1 if df row, DateTime end output df row 1, DateTime start input df row, DateTime end output df row 1, DateTime start input end end transform df , DateTime start input x round. x, Dates.Minute 10 DateTime start input 10min, rename df , MPV1 time DateTime end md\"\"\" Climate \"\"\" climate 5min let df CSV.read \".. 02 climate climate mic3 5min.csv\", DataFrame rename df, DateTime start DateTime start output, DateTime end DateTime end output df end md\"\"\" Door opening and closing \"\"\" md\"\"\" The opening and closing of the chamber's door is monitored continuously and available in the `Mic3 ouverture porte.csv` file. The `ouverture porte` columns, renamed in this notebook into `door event` has the value of 0 when a closing event of the door was registered, and 1 when it is opening. \"\"\" door df let df CSV.read \".. 00 data door opening Mic3 door opening.csv\", DataFrame select df, DateTime x Dates.DateTime. x, \"yyy mm dd HH MM SS\" DateTime, ouverture porte door event, DateTime x round. Dates.DateTime. x, \"yyy mm dd HH MM SS\" , Dates.Minute 10 DateTime 10min, combine groupby df, DateTime 10min , door event x true door event end md\"\"\" Outliers Some outliers were manually identified. These outliers are the ones that are obvious, but not identified through the door opening or a scenario change data bases. It can still come from a door opening though and it is most likely , because some door openings were not registered properly we can see some using the thermal images . \"\"\" outliers let df CSV.read \".. 00 data picarro flux outliers.csv\", DataFrame transform df , Time ByRow x floor DateTime x 1 19 , dateformat\"yyy mm ddTHH MM SS.s\" . Second 150 , Minute 1 DateTime start input select df , DateTime start input df .outlier . true unique df , DateTime start input end md\"\"\" Cleaning the data \"\"\" md\"\"\" Door opening and scenario change \"\"\" md\"\"\" The CO2 fluxes where monitored at a 10 minute time step resolution 5 min in, 5min out , so we only need to know if the door was opened or just closed in this 10min time window. To do so, we rounded the `DateTime` column to 10min, and only kept the information about a \"door event\" in this window, i.e. the door was opened and or closed in this 10min window. \"\"\" md\"\"\" Joining Joining the data into the same dataframe. The door data is merged at a 10min resolution because an event can happen just before or after the CO2 measurement window. \"\"\" md\"\"\" Here we define the number of values that will be removed before a door event or a scenario change |Event|Before|After| | | | | |Door| bind flag before opening PlutoUI.Slider 1 20, default 1, show value true | bind flag after opening PlutoUI.Slider 1 20, default 5, show value true | |Scenario| bind flag before scenario PlutoUI.Slider 1 20, default 1, show value true | bind flag after scenario PlutoUI.Slider 1 20, default 9, show value true | \"\"\" CO2 flux, climate 5min md\"\"\" note Note that we also added a variable that flags all data points around a door opening. \"\"\" md\"\"\" Visualizing \"\"\" md\"\"\" Figure 1. CO2 flux in the chamber during the whole experiment 2 months . Points are colored green when the system is not at steady state because there is a change of scenario. These points will be removed from the final database. \"\"\" md\"\"\" Figure 2. CO2 flux in the chamber during the whole experiment 2 months . Points are colored orange true when the system is not at steady state because there was a door opening closing event near the point. These points will be removed from the final database. \"\"\" md\"\"\" Figure 3. CO2 concentration in the chamber measured at valve opening. All points that are in between twwo scenarii are flagged here see below for the code \"\"\" md\"\"\" Cleaning \"\"\" md\"\"\" The CO2 fluxes are not reliable when there is a sudden change in the conditions due to an opening of the door of the chamber, or when there is a change in the CO2 scenario in the chamber, for example when changing from the 400ppm scenario to the 600ppm scenario. We then have to remove all points around these events. \"\"\" md\"\"\" Figure 4. Cleaned CO2 fluxes in the chamber during the whole experiment 2 months . \"\"\" md\"\"\" Outliers Some outliers still remain in the data base. They most likely come from a door opening that was not registered. We can see some from the thermal images. We identified those clear outliers manually. \"\"\" md\"\"\" Joining \"\"\" md\"\"\" Here is an example clear outlier happening just before 21 00 on the 1st of april \"\"\" md\"\"\" All outliers identified by hand \"\"\" md\"\"\" Filtering Now we can remove the points that were identified as outliers \"\"\" md\"\"\" Saving Saving the resulting database to disk. \"\"\" md\"\"\" References \"\"\" \"\"\" propagate around x, val, before, after Propagate the value `val` in the vector `x` around it to `before` values before the values equal to `val`, and `after` values after it. Arguments `x` a vector of values `val` a value to find and propagate inside `x` `before` number of values to propagate before `x x. val ` `after` number of values to propagate after `x x. val ` Examples ```julia julia propagate around 1,1,1,0,1,1,1,1 , 0, 1, 3 1,1,0,0,0,0,0,1 ``` \"\"\" function propagate around x, val, before, after x2 copy x Find any value in x that matches val val in x findall skipmissing x . val length val in x 0 && return For each index that matches `val`, set the value around it `before` and `after` to `val` for i in val in x x2 max 1, i before min end, i after . val end return x2 end df let df leftjoin CO2 flux, select climate 5min, Not DateTime end output , on DateTime start output leftjoin df , door df, on DateTime start input 10min DateTime 10min , makeunique true transform df , door event ByRow x ismissing x ? false x door event, CO2 change ByRow x ismissing x && x \"change\" ? true false CO2 change, Adding \"opening around\" column that flags values around a door opening or closing event. Also adding \"CO2 change around\" column that flags values that are close to a scenario change 1 before and 5 after a change . transform df , door event x propagate around x, true, flag before opening, flag after opening opening around, CO2 change x propagate around x, true, flag before scenario, flag after scenario CO2 change around df end data df mapping DateTime \"Time\", flux umol s \"CO2 flux Œºmol s‚Åª¬π \", color CO2 change around string \"Around CO2 \\nscenario change\", | draw data df mapping DateTime \"Time\", flux umol s \"CO2 flux Œºmol s‚Åª¬π \", color opening around string \"Around \\ndoor opening\", | draw let df transform df, CO2 dry MPV1 ByRow x begin x 400 || 430 x 595 || 650 x 770 || x 850 end CO2 dry MVP1 change, CO2 dry MPV2 ByRow x 430 x 550 || 650 x 720 CO2 dry MVP2 change transform df , CO2 dry MVP1 change, CO2 dry MVP2 change ByRow x, y x || y CO2 dry MVP change data df mapping DateTime \"Time\", CO2 dry MPV1 \"CO2 concentration ppm \", color CO2 dry MVP change string \"In between\", | draw end df filt let df transform df, CO2 dry MPV1 ByRow x begin x 400 || 430 x 595 || 650 x 770 || x 850 end CO2 dry MVP1 change, CO2 dry MPV2 ByRow x 430 x 550 || 650 x 720 CO2 dry MVP2 change transform df , CO2 dry MVP1 change, CO2 dry MVP2 change ByRow x, y x || y CO2 dry MVP change filter x x.opening around false && x.CO2 change around false && x.CO2 dry MVP change false, df df end max system response time Dates.Minute round unique df filt.flow m3 h 1 1.5 60 md\"\"\" `DateTime` `MPV1 time` in the file is the timestamp that marks the middle of the period of the measurement of the input fluxes of the chamber. The valve is opened during 5 minutes 2.5 min before, 2.5 min after , but the two first minutes are thrown away for purging the pipe from the previous measurement. `MPV2 time` is the middle of the period of the measurement of the output fluxes of the chamber what is interesting to us . The measurement duration is the same, 5 minutes around this time. Again, the two first minutes are not used for the computation of the fluxes as they considered as a purge. The response time of the measurement depends on the volume of the chamber, which can delay the response. For example, if we shut down the light abruptly in the chamber, the response of the plant would be close to immediate the photosynthesis would go down to zero , but we would still measure photosynthesis for a bit of time in the analyzer because of the time response of the system, as the volume of air in the chamber is big compared to the fluxes. We can compute the maximum delay without proper mixing using the chamber volume divided by the air flow m3 h 1 , which gives a maximum response time of max system response time. This is without considering air flow inside the chamber, which is well mixed. We can use two different methods to alleviate this effect a low pass filter https en.wikipedia.org wiki Low pass filter to recompute the instantaneous response an integration of the fluxes at a bigger time scale \"\"\" data df filt mapping DateTime \"Time\", flux umol s \"CO2 flux Œºmol s‚Åª¬π \", | draw df filt outliers leftjoin df filt, outliers, on DateTime start input bind day PlutoUI.Slider Date minimum df filt outliers.DateTime Day 1 Date maximum df filt outliers.DateTime , show value true, default Date \"2021 04 01\" data filter x Date x.DateTime day , df filt outliers mapping DateTime \"Time\", flux umol s \"CO2 concentration ppm \", color outlier x ismissing x ? false x \"Outlier\", | draw data df filt outliers mapping DateTime \"Time\", flux umol s \"CO2 concentration ppm \", color outlier x ismissing x ? false x \"Outlier\", | draw df filt outliers filt let df filter x ismissing x.outlier , df filt outliers select df , Not outlier end CSV.write \"CO2 fluxes.csv\", select sort df filt outliers filt, DateTime start input , DateTime start input, DateTime end input, DateTime start output, DateTime end output, CO2 dry MPV1 CO2 dry input, CO2 dry MPV2 CO2 dry output, flux umol s CO2 flux umol s TableOfContents title \"üìö Table of Contents\", indent true, depth 4, aside true "},{"url":"05-thermal_camera_measurements/2-visualize_temperature_notebook/","title":"Thermal camera data","tags":["thermal"],"text":" A Pluto.jl notebook v0.19.42 frontmatter title \"Thermal camera data\" layout \"layout.jlhtml\" description \"Measurements and visualization of the leaf temperature in the Ecotron chambers.\" tags \"thermal\" using Markdown using InteractiveUtils begin using CSV using DataFrames using CairoMakie using AlgebraOfGraphics using CodecBzip2 using Colors using Images using Makie.GeometryBasics end md\"\"\" Leaf Temperature Leaf temperature was measured with a a FLIR Vue‚Ñ¢ Pro R thermal camera that took one image every second. The camera was placed on the farthest top left corner of the chamber, pointing down towards the center of the chamber to ensure the best visibility of the plant leaves. The image database was compresses using `tar` with the `bzip2` algorithm, which reduced significantly disk space from ~60Go to ~23Go. The images were then processed in the script 1 compute leaf temperature.jl https github.com PalmStudio Biophysics database palm blob main 05 thermal camera measurements 1 compute leaf temperature.jl , resulting in a new file `leaf temperature.csv.bz2`, a compressed CSV file. Here is an example thermal image of plant 3 with a mask for leaf 3 \"\"\" let img file \".. EcotronAnalysis.jl test test data 20210308 180009 R.jpg\" mask file \".. EcotronAnalysis.jl test test data P3F3 S1 S2 S3 20210308 174136 20210309 140728 XY Coordinates.csv\" im Images.load img file ' mask CSV.read mask file, DataFrame f Figure image f 1, 1 , im, axis aspect DataAspect , yreversed true, title \"Mask for leaf 3 from plant 3\", subtitle \"Applicable from 17 41 on the 08 03 2021 to 14 07 on the 09 03 2021\", poly f 1, 1 , Polygon Point round i.X , round i.Y for i in eachrow mask , color \"red\" f end md\"\"\" Import Importing the dependencies \"\"\" md\"\"\" Reading the leaf temperature data \"\"\" leaf temperature df let df open Bzip2DecompressorStream, \"leaf temperature.csv.bz2\" do io CSV.read io, DataFrame end climate CSV.read \".. 02 climate climate mic3.csv\", DataFrame leftjoin df, climate, on DateTime end md\"\"\" Plotting \"\"\" begin abline mapping 0 , 1 visual ABLines, color grey, linestyle dash p abline AlgebraOfGraphics.data dropmissing leaf temperature df, Ta measurement mapping Ta measurement \"Air temperature ¬∞C \", Tl mean \"Leaf temperature ¬∞C \", color leaf \"Leaf Number\", layout plant string \"Plant\", visual Scatter, markersize 3 | draw end md\"\"\" Figure 1. Simulated leaf temperature y and measured air temperature x for the four plants, colored according to the leaf number. \"\"\" data dropmissing leaf temperature df, Ta measurement mapping DateTime \"DateTime UTC \", Ta measurement \"Air temperature ¬∞C \", visual Scatter, color red, markersize 1 AlgebraOfGraphics.data dropmissing leaf temperature df, Ta measurement mapping DateTime \"DateTime UTC \", Tl mean \"Leaf temperature ¬∞C \", color plant string \"Plant\", visual Scatter, markersize 3 | draw md\"\"\" Figure 2. Simulated leaf temperature for the four plants along the whole duration of the experiment. Points are colored according to the plant in the microcosm `mic3` . The red colored points represent the air temperature. \"\"\" "},{"url":"06-transpiration/transpiration_notebook/","title":"Plant transpiration data","tags":["transpiration"],"text":" A Pluto.jl notebook v0.19.43 frontmatter title \"Plant transpiration data\" layout \"layout.jlhtml\" tags \"transpiration\" description \"Processing of plant transpiration data.\" using Markdown using InteractiveUtils This Pluto notebook uses bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of bind gives bound variables a default value instead of an error . macro bind def, element quote local iv try Base.loaded modules Base.PkgId Base.UUID \"6e696c72 6542 2067 7265 42206c756150\" , \"AbstractPlutoDingetjes\" .Bonds.initial value catch b missing end local el esc element global esc def Core.applicable Base.get, el ? Base.get el iv el el end end begin using Dates using CSV, DataFrames, Statistics using CodecBzip2, Tar For the compression of the resulting CSV using AlgebraOfGraphics, CairoMakie using ShiftedArrays using PlutoUI end md\"\"\" Plant transpiration The weight of the potted plant inside the measurement chamber `mic3` was continuously monitored using a connected precision scale. The pot and soil were isolated using a plastic bag, so any change in the pot weight was due to the plant transpiration the saturation inside the bag . The transpiration was measured in five phases due to changes in the measurement setup phase 0, from 09 03 2021 to 10 03 2021, logged in the file `Weights 1.txt`. In this phase we used a regular computer with a script that read the data from the scale 1000C 3000D for one minute, and logged its average onto the computer. The DateTime is in UTC 1. phase 1, from 2021 03 10T15 08 23 to 2021 03 15T14 49 06, file `weightsPhase1.txt`. We changed computers to use one from the Ecotron, which was arounbd UTC 4min. phase 2, from 2021 03 15T15 46 13 to 2021 03 27T01 19 27, file `weightsPhase2.txt`. In this measurement phase, we changed the script to log the data every second, without any averaging as we decided it is better to log the raw data and make the average afterward. The DateTime should be close to UTC. This data collection end the day before the day time change. Data is lost for the weekend after 2021 03 27T01 19 27 because the weight of the plant was above the maximum capacity of the scale. phase 3, from 2021 03 30T09 45 01 to 2021 04 08T07 03 59, file `weightsPhase3.txt`. This phase is the same as phase 3, there is just a data gap because we were investigating why data logging was not working anymore we didn't see any error on the scale . phase 4, from 2021 04 07T10 46 19 to 2021 05 02T06 49 33, file `weightsPhase4.txt`. We received the new precision scale XB3200C that we just bought we borrowed the first one . So in this phase we changed the scale, and also installed a Raspberry Pi to log the data. The Raspberry Pi is connected to the scale via USB, and the data is logged every second. We measured a lag in the DateTime of around 1 day, 47 minutes and 12 seconds compared to UTC Raspberry 2021 04 12T13 02 43 Thermal camera 20210413 144827 R.jpg, with a delay of 3512s, so 2021 04 13T13 49 55 UTC To be sure to get the same time for all the data, we used the time of the thermal camera, which we know have a constant delay of 3512s compared to UTC. The method was to use the thermal images to see when there is a change of plant, because its weight goes down near 0.0 at this time, with a maximum error of 60s, because the images where taken each minute. We use the `time synchronization.csv` file to synchronize correctly the timestamps. \"\"\" TableOfContents title \"üìö Table of Contents\", indent true, depth 4, aside true md\"\"\" Imports Dependencies \"\"\" md\"\"\" Data Time correction Importing the file that tells us the correction to apply on the time measurement of the scale and the plant sequence. \"\"\" time correction CSV.read \".. 03 time synchronization time synchronization.csv\", DataFrame md\"\"\" Decompressing the archive \"\"\" if isdir \".. 00 data scale weight weight\" open Bzip2DecompressorStream, \".. 00 data scale weight weights.tar.bz2\" do io Tar.extract io, \".. 00 data scale weight weight\" end end md\"\"\" Import plant weight For each phase, we import the data as is `df phase x delayed` and then correct it `df phase x` \"\"\" md\"\"\" Phase 0 \"\"\" md\"\"\" Reading phase 0 data. We know this one is at UTC 1 because it was connected to R√©mi's computer, with a well synchrnonized clock. Note that we don't have the possibility to double check this one with the camera as there is no data close to 0 it starts when the plant is on, and end before removing it. \"\"\" df phase 0 delayed, df phase 0 let df raw CSV.read \".. 00 data scale weight weight weights 1.txt\", DataFrame, header \"DateTime\", \"weight\" df copy df raw df unique df , DateTime df .DateTime df .DateTime Dates.Hour 1 df raw, df end md\"\"\" Phase 1 Starting from phase 1 until phase 4 measurements, we double checked the delays between the scale data logging and UTC using the thermal camera and the time of door opening and closing, which is the reference because it is synchronized to UTC with all other equipments from the Ecotron. \"\"\" df phase 1 delayed, df phase 1 let df raw CSV.read \".. 00 data scale weight weight weightsPhase1.txt\", DataFrame, header \"DateTime\", \"weight\" df copy df raw Phase 0 is at UTC 1, so we need to correct the time delay filter x x.type \"scale\" && x.phase \"phase1\", time correction .delay seconds 1 df .DateTime . Dates.Second delay Some measurements are made twice per second, we only need once df unique df , DateTime df raw, df end md\"\"\" Phase 2 \"\"\" df phase 2 delayed, df phase 2 let df raw CSV.read \".. 00 data scale weight weight weightsPhase2.txt\", DataFrame, header \"DateTime\", \"weight\" df copy df raw Phase 0 is at UTC 1, so we need to correct the time delay filter x x.type \"scale\" && x.phase \"phase2\", time correction .delay seconds 1 df .DateTime . Dates.Second delay df unique df , DateTime df raw, df end md\"\"\" Phase 3 \"\"\" df phase 3 delayed, df phase 3 let df raw CSV.read \".. 00 data scale weight weight weightsPhase3.txt\", DataFrame, header \"DateTime\", \"weight\" df copy df raw Phase 0 is at UTC 1, so we need to correct the time delay filter x x.type \"scale\" && x.phase \"phase3\", time correction .delay seconds 1 df .DateTime . Dates.Second delay df unique df , DateTime df raw, df end md\"\"\" Phase 4 \"\"\" df phase 4 delayed, df phase 4 let df raw CSV.read \".. 00 data scale weight weight weightsPhase4.txt\", DataFrame, header \"DateTime\", \"weight\" df copy df raw Phase 0 is at UTC 1, so we need to correct the time delay filter x x.type \"scale\" && x.phase \"phase4\", time correction .delay seconds 1 df .DateTime . Dates.Second delay df unique df , DateTime df raw, df end md\"\"\" Importing CO2 Transpiration was measured every minute at the begining, and then every second. The data is noisy, but we integrate the values over the 5 min or 10 min time window of the CO2 fluxes measurements, which helps reduce the noize see below . To do that, we need to import the CO2 measurement file that gives us the precise timestamps for each measurement time window \"\"\" CO2 let df CSV.read \".. 04 CO2 CO2 fluxes.csv\", DataFrame select df , DateTime start input, DateTime end input, DateTime start output, DateTime end output, df end md\"\"\" Importing plant sequence \"\"\" md\"\"\" We want to filter out the scale measurements when a plant is moved from the scale or replaced. To do so, we can import the file that reports the plant sequences, because we know the measurement of plant weight is continuous inside a measurement sequence. We also correct the timestamps of the dates in the file as they were reported using the timestamp from the scale, with a delay that depends on the phase of measurement. \"\"\" plant sequence raw let df CSV.read \".. 00 data scenario sequence SequencePlanteMicro3.csv\", DataFrame transform df , DateTime start ByRow x DateTime x, dateformat\"dd mm yyyy HH MM SS\\'\" DateTime start, DateTime end ByRow x DateTime x, dateformat\"dd mm yyyy HH MM SS\\'\" DateTime end phase1 dates first df phase 1 delayed.DateTime , last df phase 1 delayed.DateTime delay phase1 filter x x.type \"scale\" && x.phase \"phase1\", time correction .delay seconds 1 df .DateTime start df .DateTime start. phase1 dates 1 .&&df .DateTime start. phase1 dates 2 . Dates.Second delay phase1 df .DateTime end df .DateTime end. phase1 dates 1 .&&df .DateTime end. phase1 dates 2 . Dates.Second delay phase1 phase2 dates first df phase 2 delayed.DateTime , last df phase 2 delayed.DateTime delay phase2 filter x x.type \"scale\" && x.phase \"phase2\", time correction .delay seconds 1 df .DateTime start df .DateTime start. phase2 dates 1 .&&df .DateTime start. phase2 dates 2 . Dates.Second delay phase2 df .DateTime end df .DateTime end. phase2 dates 1 .&&df .DateTime end. phase2 dates 2 . Dates.Second delay phase2 phase3 dates first df phase 3 delayed.DateTime , last df phase 3 delayed.DateTime delay phase3 filter x x.type \"scale\" && x.phase \"phase3\", time correction .delay seconds 1 df .DateTime start df .DateTime start. phase3 dates 1 .&&df .DateTime start. phase3 dates 2 . Dates.Second delay phase3 df .DateTime end df .DateTime end. phase3 dates 1 .&&df .DateTime end. phase3 dates 2 . Dates.Second delay phase3 df end plant sequence filter row row.Event \"delete transpiration\", plant sequence raw This is a day when the scale was at maximum capacity, so there is no measurement of transpiration md\"\"\" Merging the data Now that we imported the data and corrected the delays to match UTC, we can merge the plant weight data into one single dataframe. \"\"\" weight df sort vcat df phase 0, df phase 1, df phase 2, df phase 3, df phase 4 , DateTime md\"\"\" And we can also add the sequence of measurement to the dataframe so we can group by plant sequence then, and sort out the time window when we are not performing a measurement, or in the process of changing the plant inside the chamber. \"\"\" transpiration df seq let df copy weight df df .DateTime start seq Vector Union DateTime,Missing missing, nrow df df .DateTime end seq Vector Union DateTime,Missing missing, nrow df df .Plant Vector Union String,Missing missing, nrow df df .sequence Vector Union Int,Missing missing, nrow df global gp 1 Sequence group for row in eachrow plant sequence 5 min time window ismissing row.DateTime start || ismissing row.DateTime end && continue timestamps within findall row.DateTime start . df .DateTime . row.DateTime end if length timestamps within 0 df .DateTime start seq timestamps within . row.DateTime start df .DateTime end seq timestamps within . row.DateTime end df .Plant timestamps within . row.Plant df .sequence timestamps within . gp gp 1 increment the sequence group whenever we found one end end df transform df , Plant ByRow x ismissing x ? missing parse Int, x 2 Plant id df end md\"\"\" Computing the transpiration \"\"\" md\"\"\" Plotting the plants weight along the whole experiment \"\"\" data dropmissing transpiration df seq, sequence mapping DateTime \"Date UTC \", weight \"Scale weight g \", color Plant id visual Scatter | draw md\"\"\" We can see some outliers in the values. These outliers come from three different things We removed the plant from the scale to switch plants The pot was irrigated We touched the plot unintentionaly, e.g. when entering the chamber to get the camera data \"\"\" md\"\"\" Removing data below 2000 grammes Pots where never lighter than that, so values below that are either a change in plant, or no plant on the scale. \"\"\" transpiration df sup2000 filter x x.weight 2000.0, transpiration df seq md\"\"\" Removing irrigation Plants were automatically watered in mic3. The irrigation events can be retreived by seeing a sharp increase in the plant weight. We can't directly use data points with increased weight as the data can be noisy and small increase in weight can be observed from one second to the other due to measurement error. Instead, we use a threshold that is higher than measurement error, but not too high so we get the irrigation events. To remove the irrigation effect from the data, we remove the cumulative sum of the irrigation values along each session of measurement for each plant session . \"\"\" bind threshold PlutoUI.Slider 3 10, default 5.0, show value true transpiration df irrig let df dropmissing transpiration df sup2000, DateTime start seq gdf groupby df , sequence transform gdf, weight x first x . x weight rel transform gdf, weight rel x x . ShiftedArrays.lag x diff transform gdf, diff ByRow x begin ismissing x && return 0.0 x threshold ? x 0.0 end irrigation transform gdf, irrigation ByRow x x 0.0 irrigation event transform gdf, irrigation cumsum irrigation cum transform gdf, weight rel, irrigation cum w, i w . i weight rel no irrig, weight, irrigation cum w, i w . i weight no irrig, diff, irrigation w, i w . i diff no irrig, end md\"\"\" Ploting the irrigation events in the scale weights \"\"\" data transpiration df irrig mapping DateTime \"Date UTC \", weight rel \"Relative scale weight g \", color irrigation event visual Scatter | draw md\"\"\" And the plant weight corrected for irrigation \"\"\" data transpiration df irrig mapping DateTime \"Date UTC \", weight no irrig \"Weight without irrigation g \", color Plant id \"Plant ID\" visual Scatter | draw md\"\"\" Matching CO2 time scale \"\"\" md\"\"\" We compute the plant transpiration at the same time scale than the measurement of the CO2 fluxes. These fluxes are measured for 5 minutes every 10 minutes. We make two dataframes, one only with the transpiration during those 5 minutes, and one with the transpiration over the full 10 min window. The transpiration is computed following two different methods weight difference the transpiration is computed from the difference in weight between the beginning and the end of the measurement window regression the transpiration is computed using the slope of the linear regression of the weight against time for all measurement points inside the time window. \"\"\" md\"\"\" Note that the weight is highly variable, even in a 5 min time window, because of the wind inside the chamber that made the leaves move, which in turn made the weight measurement change. For example, here is a measurement for 5 min \"\"\" md\"\"\" 5 minute transpiration \"\"\" md\"\"\" In the \"difference method\", we can use only the first and last points, or if enough data point in the 5 minutes, we can take the median of several first and last points instead. We can choose the number of points used in this computation with the following slider \"\"\" bind points mean PlutoUI.Slider 1 10, default 10, show value true md\"\"\" Comparing the two methods of computing the transpiration \"\"\" md\"\"\" 10 minute transpiration \"\"\" md\"\"\" Analyses of the output \"\"\" bind date plot PlutoUI.Select \"2021 03 12\", \"2021 04 24\" md\"\"\" Saving Save the data to disk, and compressing it to save disk space. \"\"\" CSV.write \"plant sequence delayed corrected.csv\", plant sequence raw md\"\"\" References \"\"\" \"\"\" add timeperiod x,y Add DateTime start input, DateTime end input, DateTime start output and DateTime end output on a copy of dataframe `x`. \"\"\" function add timeperiod x, y df copy x df .DateTime start output Vector Union DateTime,Missing undef, nrow df df .DateTime start input Vector Union DateTime,Missing undef, nrow df df .DateTime end input Vector Union DateTime,Missing undef, nrow df df .DateTime end output Vector Union DateTime,Missing undef, nrow df y nrows nrow y for i, row in enumerate eachrow y 5 min time window ismissing row.DateTime start output || ismissing row.DateTime end output && continue timestamps within findall row.DateTime start output . df .DateTime . row.DateTime end output Don't compute time steps that covers two sequences we are changing plant here if length timestamps within 0 && length unique df .sequence timestamps within 1 df .DateTime start output timestamps within . row.DateTime start output df .DateTime end output timestamps within . row.DateTime end output end 10 min time window timestamps within findall row.DateTime start input . df .DateTime . row.DateTime end output if length timestamps within 0 && length unique df .sequence timestamps within 1 df .DateTime start input timestamps within . row.DateTime start input df .DateTime end output timestamps within . row.DateTime end output NB we add DateTime end output here for the time steps that are within the input, because we still want to know when the measurement ends end end df .DateTime end input df .DateTime start output return df end transpiration df let df add timeperiod sort dropmissing transpiration df irrig, DateTime , DateTime , CO2 transform df , DateTime x x . ShiftedArrays.lag x duration df end data groupby dropmissing transpiration df, DateTime start output , DateTime start output end mapping DateTime \"Time UTC \", weight no irrig \"Plant weight g \" | draw transpiration first 5min let df dropmissing transpiration df, DateTime start output Compute the cumulated duration over each 5 min window gdf groupby df , DateTime start output transform gdf, duration cumsum duration cum Compute transpiration as the slope of the linear weight~duration relationship df combine gdf, DateTime end output unique DateTime end, sequence unique sequence, Plant id unique Plant, weight no irrig, duration cum y, x begin first duration Second x 1 .value x i.value first duration for i in Second. x x' x \\ x' y 1 . y end transpiration g s, grammes s 1 To compute as the weight difference between first last time step s weight no irrig, duration cum x, y begin if length x 20 return median first x, 1 median last x, 1 Second last y .value Second first y .value else If enough data points, we take the median of the last 10 points for the 1s time step data with high variability For the duration, we take the average duration of the first \"points mean\" points, and the average duration of the last \"points mean\" points, because this becomes a moving window instead of jsut a point, so we need the duration between the two moving windows. We take the average window time because the size of the window can vary the durations vary . duration cumul first mean Second i .value for i in first y, points mean duration cumul last mean Second i .value for i in last y, points mean return median first x, points mean median last x, points mean duration cumul last duration cumul first end end transpiration diff g s, duration cum x canonicalize maximum x period computation, nrow, irrigation sum irrigation, rename df , DateTime start output DateTime start Keep only the time steps where we have 3 minutes of data to compute Tr filter x x.nrow 3, df filter x x.transpiration g s 0.005, df df end let p data transpiration first 5min mapping DateTime start \"Date UTC \", transpiration diff g s, transpiration g s . \"Instantaneous transpiration g \", color dims 1 renamer \"Difference\", \"Linear reg.\" visual Scatter draw p, legend position bottom, end begin f Figure ax Axis f 1, 1 , title \"Transpiration g s‚Åª¬π \", xlabel \"Difference between two consecutive points\", ylabel \"Slope of the linear regression\" ablines ax, 0.0 , 1.0 , color grey, linestyle dot scatter ax, transpiration first 5min.transpiration diff g s, transpiration first 5min.transpiration g s, color grey, 0.5 f end open Bzip2CompressorStream, \"transpiration first 5min.csv.bz2\", \"w\" do stream CSV.write stream, transpiration first 5min end transpiration 10min let df dropmissing transpiration df, DateTime start input, duration Compute the cumulated duration over each 10 min window gdf groupby df , DateTime start input transform gdf, duration cumsum duration cum Compute transpiration as the slope of the linear weight~duration relationship df combine gdf, DateTime end output unique DateTime end, sequence unique sequence, Plant id unique Plant, weight no irrig, duration cum y, x begin first duration Second x 1 .value x i.value first duration for i in Second. x x' x \\ x' y 1 . y end transpiration g s, grammes s 1 To compute as the weight difference between first last time step s weight no irrig, duration cum x, y begin if length x 20 return median first x, 1 median last x, 1 Second last y .value Second first y .value else If enough data points, we take the median of the last 10 points for the 1s time step data with high variability For the duration, we take the average duration of the first \"points mean\" points, and the average duration of the last \"points mean\" points, because this becomes a moving window instead of jsut a point, so we need the duration between the two moving windows. We take the average window time because the size of the window can vary the durations vary . duration cumul first mean Second i .value for i in first y, points mean duration cumul last mean Second i .value for i in last y, points mean return median first x, points mean median last x, points mean duration cumul last duration cumul first end end transpiration diff g s, nrow, irrigation sum irrigation, weight mean, diff no irrig sum, weight no irrig x x weight no irrig rename df , DateTime start input DateTime start Keep only the time steps where we have 3 minutes of data to compute Tr filter x x.nrow 3, df filter x x.transpiration g s 0.005, df df end let p data transpiration 10min mapping DateTime start \"Date UTC \", transpiration diff g s, transpiration g s . \"Instantaneous transpiration g \", color dims 1 renamer \"Difference\", \"Linear reg.\" visual Scatter draw p, legend position bottom, end let date to plot Date date plot df filter row row.DateTime start date to plot && row.DateTime start date to plot Day 1 , transpiration 10min p data df mapping DateTime start \"Date UTC \", transpiration diff g s, transpiration g s . \"Instantaneous transpiration g \", color dims 1 renamer \"Difference\", \"Linear reg.\" , layout visual Lines, title date to plot draw p, legend position bottom, end open Bzip2CompressorStream, \"transpiration 10min.csv.bz2\", \"w\" do stream CSV.write stream, transpiration 10min end "},{"url":"07-walz/notebook_walz/","title":"Walz data","tags":["walz"],"text":" A Pluto.jl notebook v0.19.43 frontmatter title \"Walz data\" layout \"layout.jlhtml\" tags \"walz\" description \"Walz data measurements at leaf level.\" using Markdown using InteractiveUtils begin using CSV, DataFrames using CodecBzip2, Tar For the compression of the resulting CSV using PlantSimEngine, PlantBiophysics using Dates using Impute for locf, equivalent of R's fill function using PlutoUI using Plots using Statistics using AlgebraOfGraphics, CairoMakie end md\"\"\" Response curves The leaf level response to changing conditions was measured with a Walz GFS 3000 portable chamber. Two different experiments were conducted, with a different purpose 1. half of the leaves of the plants were measured at the lab during a pre experiment, coupled with SPAD measurements. The objective of these measurements was to get the effect of leaf nitrogen content on the photosynthetic parameters of the leaf, with the hypothesis that very young leaves have low photosynthetic capacity, more mature leaves have high photosynthetic capacity, and decreasing again with age dur to remobilization. We use this dataset to fit a relationship between the SPAD and the effect on the photosynthesis parameters. 1. one leaf per plant was measured before putting the plant under different a climatic sequence in the microcosm 3. The objective is to measure the plant photosynthetic capacity just before a sequence to parameterize our models as close to reality as possible, and eventually control for the effect of plant age and any other factor. It also can be used to investigate weither systematic measurements are necessary for the simulation of a plant, or if there is an effect of the scenario on the photosynthetic capacity of the plant, e.g. is the hot and dry scenarion hard on the plant. All leaves of the plants were regularly measured for their SPAD, so we can use the pre experiment to recompute the photosynthetic capacity of each leaf on the plant based on the reference leaf. \"\"\" md\"\"\" Dependencies \"\"\" md\"\"\" Data Importing the response curves \"\"\" if isdir \".. 00 data walz walz\" open Bzip2DecompressorStream, \".. 00 data walz walz.tar.bz2\" do io Tar.extract io, \".. 00 data walz walz\" end end walz files filter x occursin r\"^P. \\.csv \", basename x , readdir \".. 00 data walz walz\", join true walz df let df read walz walz files transform df , source ByRow x begin file name basename string x parse Int, file name 2 , parse Int, file name 4 , Date string file name 5 8 , \"2021\" , dateformat\"mmddyyyy\" end Plant, Leaf, Date file name Take only the points where there are measurements for the fluorescence, because this is the last point, and else we can have different number of measurements for one forcing a step in a Walz depending on how much time we stay at this step. filter row ismissing row.Yield , df end md\"\"\" Fitting \"\"\" md\"\"\" Photosynthetic parameters The photosyntheric parameters are fitted on each response curve separately. note T·µ£ was set to 25¬∞C in the chamber. If you want to re use this code, please adapt its value. We first remove the Rh and light curves for the fitting because temperature varies in those. \"\"\" walz df CO2 filter x x.curve \"Rh Curve\" && x.curve \"light Curve\", walz df df fit CO2 let Tgrowth Thome 25.0 gdf groupby walz df CO2, Date, Plant, Leaf res for group df in gdf push res, merge Date unique group df.Date 1 , Plant unique group df.Plant 1 , Leaf unique group df.Leaf 1 , fit Fvcb, group df From Table 2 in Kumarathunge et al. 2019 T·µ£ 25.0, E‚Çê·µ• 42.6 1.14 Tgrowth 1e3, E‚Çê‚±º 40.71 1e3, Œî‚Çõ·µ• 645.13 ‚àí 0.38 Tgrowth, Œî‚Çõ‚±º 658.77 0.84 Thome 0.52 Tgrowth Thome , Note we keep both Hdj and Hdv at 200kJ mol as in Dreyer et al., 2001 and Medlyn et al., 2002. end DataFrame res end md\"\"\" Average values \"\"\" df mean CO2 combine df fit CO2, VcMaxRef, JMaxRef, RdRef, TPURef, T·µ£ . mean . VcMaxRef, JMaxRef, RdRef, TPURef, T·µ£ md\"\"\" The values are in par with the ones expected from a tropical plant and compared with the values expected from the computations presented in Kumarathunge et al. 2019 \"\"\" let Thome 25.0 DataFrame VcMaxRef only df mean CO2.VcMaxRef , JMaxRef only df mean CO2.VcMaxRef 2.56 0.0375 Thome 0.0202 , end md\"\"\" Visualization \"\"\" md\"\"\" We can now simulate the response curves with the parameters we just fitted \"\"\" df sim A let df leftjoin walz df CO2, df fit CO2, on Date, Plant, Leaf sort df , C·µ¢ dropmissing df , VcMaxRef, JMaxRef, RdRef, TPURef gdf groupby df , Date, Plant, Leaf dfs Tgrowth 25.0 Thome 25.0 for g in gdf leaf ModelList photosynthesis FvcbRaw VcMaxRef unique g.VcMaxRef 1 , JMaxRef unique g.JMaxRef 1 , RdRef unique g.RdRef 1 , TPURef unique g.TPURef 1 , From Table 2 in Kumarathunge et al. 2019 , New Phytol https doi.org 10.1111 nph.15668 E‚Çê·µ• 42.6 1.14 Tgrowth 1e3, E‚Çê‚±º 40.71 1e3, Œî‚Çõ·µ• 645.13 ‚àí 0.38 Tgrowth, Œî‚Çõ‚±º 658.77 0.84 Thome 0.52 Tgrowth Thome , Note we keep both Hdj and Hdv at 200kJ mol as in Dreyer et al., 2001 and Medlyn et al., 2002. , status T‚Çó g.T‚Çó, aPPFD g.aPPFD, C·µ¢ g.C·µ¢ run leaf df sim rename DataFrame leaf , T‚Çó T‚Çó sim, C·µ¢ C·µ¢ sim, A A sim df sim.Date g.Date df sim.Plant g.Plant df sim.Leaf g.Leaf df sim.C·µ¢ g.C·µ¢ df sim.A g.A push dfs, df sim end vcat dfs... end md\"\"\" And plot the simulation lines against the measurements points \"\"\" let lay Date, Leaf x, y string x, \" leaf \", y p data df sim A mapping C·µ¢, A, layout lay, color Plant string p sim data df sim A mapping C·µ¢ sim, A sim, layout lay, color Plant string visual Lines draw p p sim, legend position bottom, , axis width 225, height 225 end md\"\"\" Conductance parameters The conductance parameters are also fitted on each response curve separately. \"\"\" walz df Gs filter x x.curve \"light Curve\" && x.curve \"CO2 Curve\", walz df df fit Gs let gdf groupby walz df Gs, Date, Plant, Leaf res for group df in gdf g0, g1 fit Medlyn, group df if g1 0.0 g1 missing g0 missing end push res, merge Date unique group df.Date 1 , Plant unique group df.Plant 1 , Leaf unique group df.Leaf 1 , g0, g1 end DataFrame res end md\"\"\" The average results for the stomatal conductance parameters is as follows \"\"\" df mean gs combine df fit Gs, g0, g1 . x mean skipmissing x . g0, g1 md\"\"\" warning Some response curves to VPD do not allow for a fitting of the parameters because the plant did not respond properly e.g. the stomata was already closed . We put these values to `missing` instead of keeping them. \"\"\" md\"\"\" Visualization \"\"\" df sim gs let df leftjoin walz df Gs, df fit Gs, on Date, Plant, Leaf h.A meas . h.C‚Çê meas . sqrt. h.D‚Çó meas sort df , C·µ¢ dropmissing df , g0, g1 gdf groupby df , Date, Plant, Leaf dfs for g in gdf w Weather select g, T, P, Rh, C‚Çê, VPD, T x 10 Wind leaf ModelList stomatal conductance Medlyn unique g.g0 1 , unique g.g1 1 , status A g.A, C‚Çõ g.C‚Çê, D‚Çó g.D‚Çó run leaf, w df sim rename DataFrame leaf , G‚Çõ G‚Çõ sim df sim.Date g.Date df sim.Plant g.Plant df sim.Leaf g.Leaf df sim.G‚Çõ g.G‚Çõ df sim.D‚Çó g.D‚Çó df sim.C‚Çê g.C‚Çê df sim.A g.A push dfs, df sim end vcat dfs... end let df transform df sim gs, A, C‚Çê, D‚Çó A, Ca, Dl A . Ca . sqrt. Dl \"A C‚Çê‚àöD‚Çó ppm \" lay Date, Leaf x, y string x, \" leaf \", y p data df mapping \"A C‚Çê‚àöD‚Çó ppm \", G‚Çõ, layout lay, color Plant string p sim data df mapping \"A C‚Çê‚àöD‚Çó ppm \", G‚Çõ sim, layout lay, color Plant string visual Lines draw p p sim, legend position bottom, , axis width 225, height 225 end df tmp, gsAvpd let df groupby walz df Gs, Date, Plant, Leaf 1 w Weather select df , T, P, Rh, C‚Çê, VPD, T x 10 Wind g0, g1 fit Medlyn, transform df , D‚Çó VPD leaf ModelList Medlyn g0, g1 , status A df .A, C‚Çõ df .C‚Çê, D‚Çó df .D‚Çó run leaf, w Visualising the results gsAvpd PlantBiophysics.GsAD‚Çó g0, g1, df .G‚Çõ, df .VPD, df .A, df .C‚Çê, leaf G‚Çõ df , gsAvpd end md\"\"\" Here's an example of a response curve that does not allow for fitting plant unique df tmp.Plant , leaf unique df tmp.Leaf , date unique df tmp.Date \"\"\" Plots.plot gsAvpd, leg bottomright md\"\"\" And here's one that does \"\"\" let df groupby walz df Gs, Date, Plant, Leaf 5 w Weather select df , T, P, Rh, C‚Çê, VPD, T x 10 Wind g0, g1 fit Medlyn, transform df , D‚Çó VPD leaf ModelList Medlyn g0, g1 , status A df .A, C‚Çõ df .C‚Çê, D‚Çó df .D‚Çó run leaf, w Visualising the results gsAvpd2 PlantBiophysics.GsAD‚Çó g0, g1, df .G‚Çõ, df .VPD, df .A, df .C‚Çê, leaf G‚Çõ Plots.plot gsAvpd2, leg bottomright end md\"\"\" Joining the results Join the photosynthetic and conductance parameters into a single DataFrame. \"\"\" db let df outerjoin df fit CO2, df fit Gs, on Date, Plant, Leaf Columns to average over to average names df , Union Float64,Missing transform groupby df , Plant, Leaf , to average . x begin no missing vals collect skipmissing x length no missing vals 0 ? missing mean no missing vals end . string. to average, \" mean leaf\" , transform groupby df , Plant , to average . x begin no missing vals collect skipmissing x length no missing vals 0 ? missing mean no missing vals end . string. to average, \" mean plant\" , df end md\"\"\" Saving the results \"\"\" CSV.write \"photosynthetic and stomatal parameters.csv\", db md\"\"\" References Kumarathunge, D.P., Medlyn, B.E., Drake, J.E., et al., 2019 , Acclimation and adaptation components of the temperature dependence of plant photosynthesis at the global scale. New Phytol, 222 768 784. https doi.org 10.1111 nph.15668 \"\"\" TableOfContents title \"üìö Table of Contents\", indent true, depth 4, aside true "},{"url":"08-spad/notebook_spad/","title":"Spad data","tags":["spad"],"text":" A Pluto.jl notebook v0.19.43 frontmatter title \"Spad data\" layout \"layout.jlhtml\" tags \"spad\" description \"Plant response to experiments using Spad data in the Ecotron chambers.\" using Markdown using InteractiveUtils begin using CSV, DataFrames, Dates using CairoMakie, AlgebraOfGraphics using PlutoUI using GLM end md\"\"\" SPAD Introduction We made two types of SPAD measurements 1. During the pre experiment see 07 walz , where we made response curves at the leaf level for half the leaves of the plant during a week during four weeks 4 plants , we made three SPAD measurements on and around the position of the Walz GFS 3000 head. The objective here is to link SPAD measurements to photosynthetic parameters of a leaf, with the hypothesis that very young leaves have lower photosynthetic efficiency, mature leaves have the highest, and then lowering again with age. 2. During the Ecotron experiment, to be able to recompute the photosynthetic parameters of all leaves in the plant based on their SPAD and a response curve made on the reference leaf. Dependencies \"\"\" md\"\"\" Data SPAD Importing the SPAD measurements. We have two different source of data 1. SPAD measured on all leaves of all plants on the same date, repeated on two different dates 2021 02 16 and 2021 02 23. \"\"\" SPAD all leaves CSV.read \".. 00 data spad SPAD all plants.csv\", DataFrame md\"\"\" 2. SPAD measured for all leaves in the plant of interest, dependening on the sequence. \"\"\" SPAD sequence let df CSV.read \".. 00 data spad SPAD.csv\", DataFrame filter x x.SPAD 0, df transform df , Date x Date. x, dateformat\"dd mm yyyy\" Date end md\"\"\" note Some measurements of SPAD were at 0 due to a problem in the instrument. We don't keep those values. \"\"\" md\"\"\" Photosynthetic parameters Importing the results of adjusting the FvCB Farquhar‚Äìvon Caemmerer‚ÄìBerry model for C3 photosynthesis Farquhar et al., 1980 von Caemmerer and Farquhar, 1981 and the Medlyn et al. 2011 model of stomatal conductance on response curves taken with a Walz GFS 3000. \"\"\" parameters CSV.read \".. 07 walz photosynthetic and stomatal parameters.csv\", DataFrame md\"\"\" Visualizations \"\"\" md\"\"\" Comparing SPAD between plants \"\"\" md\"\"\" Visualizing SPAD measurement on all leaves of all plants on the same dates \"\"\" data SPAD all leaves mapping Leaf string, SPAD, color Plant string, layout Date | draw md\"\"\" The relationship bewteen SPAD and leaf rank seams quite conservative between plants and date of measurement. Let's look at the data with a different angle, using a layout for each plant and coloring by date, using lines to represent the relationship \"\"\" let p data SPAD all leaves mapping Leaf string, SPAD, color Date, layout Plant x string \"Plant \", x visual Lines draw p, legend position bottom, end md\"\"\" We see that the relationship is not exactly the same between plants, especially for the younger leaf that sometimes present low SPAD values. This is probably related to the age of the first leaf that can differ between plants. We don't know the date of emission of the leaf, so we cannot compute the true effect of age unfortunately. We can also look at more data using the second data base. \"\"\" md\"\"\" SPAD distribution in plants Vizualising the SPAD values for each leaf of each plant according to the date of measurement. \"\"\" let p data SPAD sequence mapping Leaf, SPAD, color Date string, layout Plant x string \"Plant \", x visual Lines draw p, legend position bottom, end md\"\"\" We can see that SPAD values are quite conservative according to the rank of the leaf on the palm. This time, only plant 1 and 4 have oldest leaves with lower values, which is an indicator of nitrogen remobilization. note The rank is the reverse of the leaf number, rank 1 is the youngest leaf e.g. leaf 10 , rank 10 the oldest e.g. leaf 1 \"\"\" md\"\"\" Relating photosynthetic parameters to SPAD \"\"\" md\"\"\" Joining data \"\"\" df all let leftjoin parameters, vcat SPAD all leaves, SPAD sequence , on Date, Plant, Leaf end md\"\"\" Visualizing SPAD~parameters relationships \"\"\" md\"\"\" SPAD The value of the SPAD tends to be higher on the more mature leaves lower leaf ID, higher rank . \"\"\" let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping Leaf, SPAD, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" SPAD also decrease with time when considering the same leaf look at the points with the same color in a layout \"\"\" let df dropmissing df all, SPAD p data df mapping Date, SPAD, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" VcMaxRef \"\"\" md\"\"\" We see that the value of VcMaxRef on the same reference leaf decreases with time. This is probably coming from a remobilization of Nitrogen as the leaf becomes older. We also see that leaves have different VcMaxRef values, and that as expected leaf rank seems to explain that variability \"\"\" let df dropmissing df all, SPAD p data df mapping Date, VcMaxRef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" If we look at the points taken before the ecotron experiment to remove the dynamic, we see that indeed VcMaxRef depends on the rank of the leaf, with young leaves having low values, more mature leaves have the highest values, and decreasing with age except for plant 4 that has a very high value for its youngest leaf \"\"\" let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping Leaf, VcMaxRef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" We can relate the value of VcMaxRef observed along the leaf rank with the SPAD \"\"\" let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping SPAD, VcMaxRef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" Unfortunately, the relationship we expected is not visible here, the SPAD does not seem to explain VcMaxRef well. Lets look at the dynamic data taken at different times, mostly on the same leaf along the Ecotron experiment \"\"\" let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping SPAD, VcMaxRef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" That's better We can see a positive relationship between SPAD and VcMaxRef. Let's look at the same data but for all plants together \"\"\" let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping SPAD, VcMaxRef, color Plant string visual Scatter draw p, legend position bottom, end md\"\"\" OK even much better. We can clearly see the effect of SPAD on VcMaxRef here. \"\"\" md\"\"\" JMaxRef \"\"\" md\"\"\" Similarly to VcMaxRef, JmaxRef seems to decrease with time when looking at the same leaf over time \"\"\" let df dropmissing df all, SPAD p data df mapping Date, JMaxRef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" Again, we observe a similar result when comparing JMaxRef between leaves of the same plant around the same date \"\"\" let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping Leaf, JMaxRef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" ... and the relationship with SPAD is also not that clear at this time \"\"\" let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping SPAD, JMaxRef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" But a little bit better looking at the dynamic data \"\"\" let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping SPAD, JMaxRef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" And mixing all plants together shows a relationship \"\"\" let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping SPAD, JMaxRef, color Plant string visual Scatter draw p, legend position bottom, end md\"\"\" Two of the values are very high though. \"\"\" md\"\"\" RdRef \"\"\" md\"\"\" RdRef seems more complicated to explain \"\"\" let df dropmissing df all, SPAD p data df mapping Date, RdRef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" As expected, there is no relationship between the value of RdRef and the leaf age \"\"\" let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping Leaf, RdRef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" This is confirmed when using all the data \"\"\" let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping SPAD, RdRef, color Plant string visual Scatter draw p, legend position bottom, end md\"\"\" RdRef will not be used to adjust the photosynthetic parameters between leaves. \"\"\" md\"\"\" TPURef \"\"\" md\"\"\" The relationship is not very clear either with TPURef, with the same graphs as before below \"\"\" let df dropmissing df all, SPAD p data df mapping Date, TPURef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping Leaf, TPURef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping SPAD, TPURef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD p data df mapping SPAD, TPURef, layout Plant x string \"Plant \", x , color Leaf string visual Scatter draw p, legend position bottom, end md\"\"\" Looking at plant scale data, we could think there might be a relationship Plant 3 , but when mixing all data the relationship is not clear \"\"\" let p data dropmissing df all, SPAD mapping SPAD, TPURef, color Plant string visual Scatter draw p, legend position bottom, end md\"\"\" We will make further investigation below before including TPURef to model photosynthesis according to leaf rank. \"\"\" md\"\"\" g0 \"\"\" let p data dropmissing df all, g0, SPAD mapping SPAD, g0, layout Plant x string \"Plant \", x visual Scatter draw p, legend position bottom, end let df dropmissing filter x x.Date Date \"2021 03 01\" , df all , SPAD, g0 p data df mapping SPAD, g0, color Plant string visual Scatter draw p, legend position bottom, end md\"\"\" g0 will not be used to adjust the photosynthetic parameters between leaves. \"\"\" md\"\"\" g1 \"\"\" let p data dropmissing df all, g0, SPAD mapping SPAD, g1, layout Plant x string \"Plant \", x visual Scatter draw p, legend position bottom, end let p data dropmissing df all, g0, SPAD mapping SPAD, g1, color Plant string visual Scatter draw p, legend position bottom, end md\"\"\" g1 will not be used to adjust the photosynthetic parameters between leaves. \"\"\" md\"\"\" Modelling In this section, we make a model that relates SPAD to the VcMaxRef photosynthetic parameter of the leaf. Ideally, we would also correlate the other parameters e.g. JMaxRef to the SPAD, but they can be highly correlated, so what we do instead is predict VcMaxRef with the SPAD, and then predict the others from VcMaxRef. \"\"\" md\"\"\" VcMaxRef~SPAD \"\"\" md\"\"\" We use a simple linear model to predict the value of VcMaxRef from the SPAD value. We use all the data from all plants because the data is noisy, and the response should be specific, which is confirmed by the figure below. \"\"\" lm VcMaxRef lm formula VcMaxRef ~ 0 SPAD , df all let df dropmissing df all, g0, SPAD df .VcMaxRef predicted predict lm VcMaxRef, df p data df mapping SPAD \"SPAD \", VcMaxRef \"VcMaxRef Œºmol m‚Åª¬≤ s‚Åª¬π \", color Plant string visual Scatter data df mapping SPAD \"SPAD \", VcMaxRef predicted \"VcMaxRef Œºmol m‚Åª¬≤ s‚Åª¬π \" visual Lines draw p, legend position bottom, end Markdown.parse \"\"\" tip The model is as follows lm VcMaxRef.mf.f.lhs.sym ‚âÉ round coef lm VcMaxRef 1 , digits 3 ‚ãÖ lm VcMaxRef.mf.f.rhs.terms 2 \"\"\" md\"\"\" The model fits well the data, and presents an R¬≤ of round r2 lm VcMaxRef , digits 2 \"\"\" md\"\"\" If we look at its performance at the plant level, we see that indeed we should use all the data, because some plants have a high variability on the value, and the average fit seems close enough to the per plant trend except for Plant 4 that has only 3 points . \"\"\" let df dropmissing df all, g0, SPAD df .VcMaxRef predicted predict lm VcMaxRef, df p data df mapping SPAD \"SPAD \", VcMaxRef \"VcMaxRef Œºmol m‚Åª¬≤ s‚Åª¬π \", layout Plant string visual Scatter data df mapping SPAD \"SPAD \", VcMaxRef predicted \"VcMaxRef Œºmol m‚Åª¬≤ s‚Åª¬π \", layout Plant string visual Lines draw p, legend position bottom, end let df dropmissing df all, SPAD, VcMaxRef df .lm VcMaxRef predicted predict lm VcMaxRef, df p mod data df mapping VcMaxRef \"Observed Œºmol m‚Åª¬≤ s‚Åª¬π \", lm VcMaxRef predicted \"Simulated Œºmol m‚Åª¬≤ s‚Åª¬π \", color Plant string visual Scatter abline mapping 0 , 1 visual ABLines, color grey, linestyle dash draw p mod abline , legend position bottom, , axis title \"VcMaxRef\", end md\"\"\" Correlations between parameters JmaxRef~VcMaxRef \"\"\" md\"\"\" JMaxRef is highly correlated with VcMaxRef, so we can't really de couple the value of one from another. We will model its change according to the modeled value of VcMaxRef of the leaf instead of its SPAD, as it helps us take into consideration their correlation. \"\"\" lm JMaxRef lm formula JMaxRef ~ 0 VcMaxRef , df all let df dropmissing df all, JMaxRef, VcMaxRef p data df mapping VcMaxRef \"VcMaxRef Œºmol m‚Åª¬≤ s‚Åª¬π \", JMaxRef \"JMaxRef Œºmol m‚Åª¬≤ s‚Åª¬π \", color Plant string visual Scatter df .lm JMaxRef predicted predict lm JMaxRef, df p mod data df mapping VcMaxRef \"VcMaxRef Œºmol m‚Åª¬≤ s‚Åª¬π \", lm JMaxRef predicted \"JMaxRef Œºmol m‚Åª¬≤ s‚Åª¬π \" visual Lines draw p mod p, legend position bottom, end Markdown.parse \"\"\" tip The model is as follows lm JMaxRef.mf.f.lhs.sym ‚âÉ round coef lm JMaxRef 1 , digits 3 ‚ãÖ lm JMaxRef.mf.f.rhs.terms 2 \"\"\" let df dropmissing df all, JMaxRef, VcMaxRef df .lm JMaxRef predicted predict lm JMaxRef, df p mod data df mapping JMaxRef \"Observed Œºmol m‚Åª¬≤ s‚Åª¬π \", lm JMaxRef predicted \"Simulated Œºmol m‚Åª¬≤ s‚Åª¬π \", color Plant string visual Scatter abline mapping 0 , 1 visual ABLines, color grey, linestyle dash draw p mod abline , legend position bottom, , axis title \"JMaxRef\", end md\"\"\" TPURef~VcMaxRef \"\"\" md\"\"\" Similarly, TPURef is also highly correlated with VcMaxRef. We will model its change according to the modeled value of VcMaxRef of the leaf instead of its SPAD, as it helps us take into consideration their correlation. \"\"\" lm TPURef lm formula TPURef ~ 0 VcMaxRef , df all let p data dropmissing df all, g0, SPAD mapping VcMaxRef, TPURef, color Plant string visual Scatter draw p, legend position bottom, df dropmissing df all, TPURef, VcMaxRef p data df mapping VcMaxRef \"VcMaxRef Œºmol m‚Åª¬≤ s‚Åª¬π \", TPURef \"TPURef Œºmol m‚Åª¬≤ s‚Åª¬π \", color Plant string visual Scatter df .lm TPURef predicted predict lm TPURef, df p mod data df mapping VcMaxRef \"VcMaxRef Œºmol m‚Åª¬≤ s‚Åª¬π \", lm TPURef predicted \"TPURef Œºmol m‚Åª¬≤ s‚Åª¬π \" visual Lines draw p mod p, legend position bottom, end Markdown.parse \"\"\" tip The model is as follows lm TPURef.mf.f.lhs.sym ‚âÉ round coef lm TPURef 1 , digits 3 ‚ãÖ lm TPURef.mf.f.rhs.terms 2 \"\"\" md\"\"\" Comparing observed and simulated TPURef \"\"\" let df dropmissing df all, VcMaxRef, TPURef df .lm TPURef predicted predict lm TPURef, df p mod data df mapping TPURef \"Observed Œºmol m‚Åª¬≤ s‚Åª¬π \", lm TPURef predicted \"Simulated Œºmol m‚Åª¬≤ s‚Åª¬π \", color Plant string visual Scatter abline mapping 0 , 1 visual ABLines, color grey, linestyle dash draw p mod abline , legend position bottom, , axis title \"TPURef\", end md\"\"\" RdRef~VcMaxRef \"\"\" let p data dropmissing df all, g0, SPAD mapping VcMaxRef \"VcMaxRef Œºmol m‚Åª¬≤ s‚Åª¬π \", RdRef \"RdRef Œºmol m‚Åª¬≤ s‚Åª¬π \", color Plant string visual Scatter draw p, legend position bottom, end md\"\"\" RdRef was not explained by the SPAD, and as we can see it is confirmed when we see that it is not correlated with VcMaxRef. \"\"\" md\"\"\" Summary We model the effect of leaf age on the photosynthetic parameters using SPAD as a proxy of the chlorophyll content. The data showed there is a clear relationship between VcMaxRef, JMaxRef, and in a lesser extent TPURef with SPAD. The three parameters are correlated, so we prefer modulating the the values of the parameters according to SPAD by using 1 a linear model between SPAD and VcMaxRef, and 2 a relationship between VcMaxRef and JMaxRef or TPURef. This way we control for the correlation between the parameters. The resulting models are the following VcMaxRef ‚âÉ round coef lm VcMaxRef 1 , digits 3 ‚ãÖ SPAD JMaxRef ‚âÉ round coef lm JMaxRef 1 , digits 3 ‚ãÖ VcMaxRef TPURef ‚âÉ round coef lm TPURef 1 , digits 3 ‚ãÖ VcMaxRef \"\"\" CSV.write \"SPAD models.csv\", DataFrame variable VcMaxref, JMaxRef, TPURef , predictor SPAD, VcMaxref, VcMaxref , coefficient coef lm VcMaxRef 1 , coef lm JMaxRef 1 , coef lm TPURef 1 md\"\"\" References \"\"\" md\"\"\" Caemmerer, S. von, et G. D. Farquhar. 1981. ¬´ Some Relationships between the Biochemistry of Photosynthesis and the Gas Exchange of Leaves ¬ª. Planta 153 4 376‚Äë87. https doi.org 10.1007 BF00384257. Farquhar, G. D., S. von von Caemmerer, et J. A. Berry. 1980. ¬´ A biochemical model of photosynthetic CO2 assimilation in leaves of C3 species ¬ª. Planta 149 1 78‚Äë90. Medlyn, B. E., E. Dreyer, D. Ellsworth, M. Forstreuter, P. C. Harley, M. U. F. Kirschbaum, X. Le Roux, et al. 2002. ¬´ Temperature response of parameters of a biochemically based model of photosynthesis. II. A review of experimental data ¬ª. Plant, Cell & Environment 25 9 1167‚Äë79. https doi.org 10.1046 j.1365 3040.2002.00891.x. \"\"\" TableOfContents title \"üìö Table of Contents\", indent true, depth 4, aside true "},{"url":"09-database/database_notebook/","title":"Database of all processed data","tags":["database"],"text":" A Pluto.jl notebook v0.19.43 frontmatter title \"Database of all processed data\" layout \"layout.jlhtml\" tags \"database\" description \"Database of all processed data.\" using Markdown using InteractiveUtils This Pluto notebook uses bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of bind gives bound variables a default value instead of an error . macro bind def, element quote local iv try Base.loaded modules Base.PkgId Base.UUID \"6e696c72 6542 2067 7265 42206c756150\" , \"AbstractPlutoDingetjes\" .Bonds.initial value catch b missing end local el esc element global esc def Core.applicable Base.get, el ? Base.get el iv el el end end begin using CSV, DataFrames using CodecBzip2, Tar , ZipFile using Dates using Statistics using PlutoUI using CairoMakie, AlgebraOfGraphics end md\"\"\" Database In this notebook, we join all the data from the different sensors into one single database. Dependencies \"\"\" md\"\"\" Data \"\"\" md\"\"\" Climate Climatic conditions inside the chamber, at 5 min time step resolution, only for the 5 minute long output flux measurement by the Picarro, not when it is measuring the input flux to the chamber. \"\"\" climate 5min CSV.read \".. 02 climate climate mic3 5min.csv\", DataFrame climate 10min CSV.read \".. 02 climate climate mic3 10min.csv\", DataFrame md\"\"\" Scenario sequence Each plant was monitored in the microcosm 3 for a sequence of one or more scenario. We have a database of all sequences during the two months experiment that helps remembering which plant is being measured for a time step, and which scenario is being done on that day. The column \"Ref\" indicates the date when the data for a specific scenario and plant is most comprehensive. \"\"\" df scenario let df CSV.read \".. 00 data scenario sequence SequenceScenarioMicro3.csv\", DataFrame transform df , Date x Date. x, dateformat\"dd mm yyyy\" Date df end md\"\"\" The sequence is available from this file \"\"\" df sequence let df CSV.read \".. 06 transpiration plant sequence delayed corrected.csv\", DataFrame transform df , Plant ByRow x parse Int, x 2 Plant df .sequence . 1 nrow df df end md\"\"\" Transpiration Plant transpiration, averaged for the 5 minute time window of the CO2 output measurement, or the full 10 min input output measurement. \"\"\" transpiration 5min open Bzip2DecompressorStream, \".. 06 transpiration transpiration first 5min.csv.bz2\" do io CSV.read io, DataFrame end transpiration 10min open Bzip2DecompressorStream, \".. 06 transpiration transpiration 10min.csv.bz2\" do io CSV.read io, DataFrame end md\"\"\" CO2 fluxes CO2 fluxes, measured every 10 minutes for 5 minutes. The first five minutes are used for measuring the input flux, the second 5 minutes for the output fluxes, i.e. the ones of interest. \"\"\" CO2 let df CSV.read \".. 04 CO2 CO2 fluxes.csv\", DataFrame end md\"\"\" Leaf temperature Leaf temperature measured by the thermal camera, at one minute time scale, for each visible leaf of the plants. The measured values must be aggregated to match the CO2 measurement coarser time scale before joining. The CO2 database provides measurements for CO2 every 10 minutes, with measurements for 5 minutes, and then measuring the input flux for 5 minutes. \"\"\" md\"\"\" We start by computing four new columns inside the one minute time scale dataframe the start and end datetime for every 5 minute window where we have a measurement of the output for the CO2 flux, and the same for every 10 minute window input and output . note The time windows are taken from the `CO2` dataframe. \"\"\" md\"\"\" 5 minute time scale Based on the previous dataframe, we can now keep only the first 5 minutes of every 10 minutes window, and average the values within those 5 minutes. The results are available in `leaf temperature first 5min`. \"\"\" md\"\"\" 10 minute time scale We can also perform a similar computation, but keeping all data in the 10 minute window for our average. \"\"\" md\"\"\" Biophysical parameters Leaf scale measurements where performed on a reference leaf before each scenario sequence with a portable gas exchange analyser Walz GFS 3000 . These measurements are used to compute the photosynthetic and stomatal conductance parameters for the model of Farquhar et al. 1980 and Medlyn et al. 2011 respectively see this notebook https github.com PalmStudio Biophysics database palm blob main 07 walz notebook walz.jl . \"\"\" df parameters let df CSV.read \".. 07 walz photosynthetic and stomatal parameters.csv\", DataFrame sort df , Date, Plant, Leaf end md\"\"\" Joining the parameters with the plant sequence \"\"\" df sequence params let last params for row in eachrow df sequence last parameters plant filter x x.Plant row.Plant && x.Date Date row.DateTime start , df parameters end , rename last parameters plant, Date Date walz, Leaf Leaf walz last parameters plant.DateTime start . row.DateTime start push last params, last parameters plant end leftjoin df sequence, vcat last params... , on DateTime start, Plant , makeunique true end md\"\"\" note The parameters associated to a plant sequence are the ones measured on the date that is closest to the start of the sequence i.e. just before . \"\"\" md\"\"\" Leaf area We measured the area of each leaf on the plants at the end of the experiment. We then computed the total leaf area of the plant, that we can transform into the LAI using the chamber soil surface. \"\"\" surface let reconstruction dir \".. 00 data lidar reconstructions\" if isdir reconstruction dir open Bzip2DecompressorStream, \".. 00 data lidar reconstructions.tar.bz2\" do io Tar.extract io, reconstruction dir end end f readdir reconstruction dir, join true surface file index findfirst x x \"surface.csv\", basename i for i in f df CSV.read f surface file index , DataFrame, dateformat dateformat\"dd mm yyyy\", delim \" \", ignorerepeated true select df , Date, plant ByRow x parse Int, x 2 Plant, PLA x x . 113.0 114.0 LAI, 113.0 114.0 is the chamber dimensions df end md\"\"\" Join Joining the databases into one single database. \"\"\" md\"\"\" 5 minute database \"\"\" md\"\"\" 10 minute database \"\"\" md\"\"\" CO2 flux \"\"\" md\"\"\" H2O flux \"\"\" md\"\"\" Leaf temperature \"\"\" md\"\"\" Saving Saving both databases to disk \"\"\" md\"\"\" Saving the measured plant surfaces \"\"\" CSV.write \"plant surface.csv\", surface md\"\"\" References \"\"\" \"\"\" duration x Computes the duration between each element starting from the first one to the second until the end. The last value has a duration of `zero x 2 x 1 `. \"\"\" function duration x len length x d fill zero x 2 x 1 , len for i in eachindex x i len && continue d i x i 1 x i end return d end \"\"\" group timesteps x, threshold Minute 10 Group time steps by a duration given by `threshold`. \"\"\" function group timesteps x, threshold Minute 10 durations duration x x group zeros Int64, length x group 0 current duration zero typeof durations 1 for i in eachindex x current duration durations i if current duration threshold group group 1 current duration zero typeof durations 1 end x group i group end return x group end \"\"\" dates between x, start dates, end dates Computes all dates in x that are in between start dates and end dates. \"\"\" function dates between x, start dates, end dates assert length start dates length end dates DateTime start Vector Union DateTime,Missing undef, length x DateTime end Vector Union DateTime,Missing undef, length x for i in eachindex start dates timestamps within findall start dates i . x . end dates 1 if length timestamps within 0 DateTime start timestamps within . DateTime start DateTime end timestamps within . DateTime end end end return DateTime start, DateTime end end \"\"\" add timeperiod x,y Add DateTime start input, DateTime end input, DateTime start output and DateTime end output on a copy of dataframe `x`. \"\"\" function add timeperiod x, y df copy x df .DateTime start output Vector Union DateTime,Missing undef, nrow df df .DateTime start input Vector Union DateTime,Missing undef, nrow df df .DateTime end input Vector Union DateTime,Missing undef, nrow df df .DateTime end output Vector Union DateTime,Missing undef, nrow df y nrows nrow y for i, row in enumerate eachrow y 5 min time window ismissing row.DateTime start output || ismissing row.DateTime end output && continue timestamps within findall row.DateTime start output . df .DateTime . row.DateTime end output Don't compute time steps that covers two sequences we are changing plant here if length timestamps within 0 df .DateTime start output timestamps within . row.DateTime start output df .DateTime end output timestamps within . row.DateTime end output end 10 min time window timestamps within findall row.DateTime start input . df .DateTime . row.DateTime end output if length timestamps within 0 df .DateTime start input timestamps within . row.DateTime start input df .DateTime end output timestamps within . row.DateTime end output NB we add DateTime end output here for the time steps that are within the input, because we still want to know when the measurement ends end end df .DateTime end input df .DateTime start output return df end leaf temperature open Bzip2DecompressorStream, \".. 05 thermal camera measurements leaf temperature.csv.bz2\" do io df CSV.read io, DataFrame select df , Not mask df add timeperiod df , CO2 select df , plant, leaf, DateTime, DateTime start input, DateTime end input, DateTime start output, DateTime end output, Tl mean, Tl min, Tl max, Tl std df end leaf temperature 5min let df filter x ismissing x.DateTime start output , leaf temperature df combine groupby df , plant, leaf, DateTime start output , DateTime end output x unique x DateTime end, names leaf temperature, Float64 . mean, nrow renamecols false rename df , DateTime start output DateTime start select df , plant, leaf, DateTime start, DateTime end, Tl mean, Tl min, Tl max, Tl std df end db 5min let db leftjoin CO2, climate 5min, on DateTime start output DateTime start , makeunique true db leftjoin db , transpiration 5min, on DateTime start output DateTime start , makeunique true db leftjoin db , leaf temperature 5min, on DateTime start output DateTime start , makeunique true transform db , DateTime start output x Date. x Date db leftjoin db , df scenario, on Date, makeunique true filter row ismissing row.Plant 1 , db Adding the plant sequence y nrows nrow df sequence params db .DateTime start sequence Vector Union DateTime,Missing undef, nrow db db .DateTime end sequence Vector Union DateTime,Missing undef, nrow db for i, row in enumerate eachrow df sequence params ismissing row.DateTime start || ismissing row.DateTime end && continue timestamps within findall row.DateTime start . db .DateTime start output . row.DateTime end Don't compute time steps that covers two sequences we are changing plant here if length timestamps within 0 db .DateTime start sequence timestamps within . row.DateTime start db .DateTime end sequence timestamps within . row.DateTime end end end End of plant sequence computation select db , Scenario, Plant 1 Plant, leaf Leaf, DateTime start output, DateTime end output DateTime end, DateTime end DateTime end CO2 in, DateTime start sequence, DateTime end sequence, DateTime end CO2 in, CO2 flux umol s CO2 outflux umol s, CO2 dry input, CO2 dry output, Ta instruction, Ta measurement, Rh instruction, Rh measurement, R instruction, R measurement, CO2 ppm, CO2 flux CO2 influx, CO2 instruction, transpiration g s transpiration linear g s, transpiration diff g s, irrigation, Tl mean, Tl min, Tl max, Tl std, Adding the biophysical parameters now that we have the Plant properly set db leftjoin db , select df sequence params, Not DateTime end, Event , on DateTime start sequence DateTime start , makeunique true, matchmissing notequal rename db , DateTime start output DateTime start, sequence Sequence, T·µ£ Tr, T·µ£ mean leaf Tr mean leaf, T·µ£ mean plant Tr mean plant Re order columns select db , DateTime start, DateTime end, Scenario, Sequence, Plant, Leaf, DateTime start sequence, DateTime end sequence, filter row ismissing row.Scenario && ismissing row.Plant , db db end md\"\"\" Visualize Let's first and last date to plot between min date minimum Date. db 5min.DateTime start and max date maximum Date. db 5min.DateTime start \"\"\" md\"\"\" bind first date PlutoUI.Slider min date Day 1 max date, default min date, show value true bind last date PlutoUI.Slider min date Day 1 max date, default max date, show value true \"\"\" let df dropmissing db 5min, DateTime end, CO2 outflux umol s, Scenario, filter x x.DateTime start first date && x.DateTime end last date, df p data df mapping DateTime start, CO2 outflux umol s, color Scenario string visual Scatter draw p end let df dropmissing db 5min, DateTime end, transpiration linear g s, Scenario, filter x x.DateTime start first date && x.DateTime end last date, df p data df mapping DateTime start, transpiration linear g s, color Scenario string visual Scatter draw p end let df dropmissing db 5min, DateTime end, Tl mean, filter x x.DateTime start first date && x.DateTime end last date, df p data df mapping DateTime start, Tl mean, color Scenario string visual Scatter draw p end pTemp all let df dropmissing db 5min, DateTime end, Tl mean, Scenario, Plant transform groupby df , Plant, Scenario, Sequence , DateTime start x 1 length x time numeric filter x x.DateTime start first date && x.DateTime end last date, df p data df mapping DateTime start Time \"Time\", Tl mean, color Leaf, row Scenario, col Plant string visual Scatter draw p, axis width 150, height 200, xticks datetimeticks df .DateTime start, Dates.format. df .DateTime start, \"HH MM\" , facet linkxaxes none end open Bzip2CompressorStream, \"database 5min.csv.bz2\", \"w\" do stream CSV.write stream, db 5min end leaf temperature 10min let df filter x ismissing x.DateTime start input , leaf temperature df combine groupby df , plant, leaf, DateTime start input , DateTime end output x unique x DateTime end, names leaf temperature, Float64 . mean, nrow renamecols false rename df , DateTime start input DateTime start select df , plant, leaf, DateTime start, DateTime end, Tl mean, Tl min, Tl max, Tl std df end db 10min let db leftjoin CO2, climate 10min, on DateTime start input DateTime start , makeunique true db leftjoin db , transpiration 10min, on DateTime start input DateTime start , makeunique true db leftjoin db , leaf temperature 10min, on DateTime start input DateTime start , makeunique true transform db , DateTime start input x Date. x Date db leftjoin db , df scenario, on Date, makeunique true filter row ismissing row.Plant 1 , db Adding the plant sequence y nrows nrow df sequence params db .DateTime start sequence Vector Union DateTime,Missing undef, nrow db db .DateTime end sequence Vector Union DateTime,Missing undef, nrow db for i, row in enumerate eachrow df sequence ismissing row.DateTime start || ismissing row.DateTime end && continue timestamps within findall row.DateTime start . db .DateTime start output . row.DateTime end Don't compute time steps that covers two sequences we are changing plant here if length timestamps within 0 db .DateTime start sequence timestamps within . row.DateTime start db .DateTime end sequence timestamps within . row.DateTime end end end End of plant sequence computation select db , Scenario, Plant 1 Plant, leaf Leaf, DateTime start input DateTime start, DateTime end output DateTime end, DateTime start output DateTime start CO2 in, DateTime start sequence, DateTime end sequence, CO2 flux umol s CO2 outflux umol s, CO2 dry input, CO2 dry output, Ta instruction, Ta measurement, Rh instruction, Rh measurement, R instruction, R measurement, CO2 ppm, CO2 flux CO2 influx, CO2 instruction, transpiration g s transpiration linear g s, transpiration diff g s, irrigation, Tl mean, Tl min, Tl max, Tl std, Adding the biophysical parameters now that we have the Plant properly set db leftjoin db , select df sequence params, Not DateTime end, Event , on DateTime start sequence DateTime start , makeunique true, matchmissing notequal rename db , DateTime start output DateTime start, sequence Sequence, T·µ£ Tr, T·µ£ mean leaf Tr mean leaf, T·µ£ mean plant Tr mean plant Re order columns select db , DateTime start, DateTime end, Scenario, Sequence, Plant, Leaf, DateTime start sequence, DateTime end sequence, filter row ismissing row.Scenario && ismissing row.Plant , db db end pCO2 all let df dropmissing db 10min, DateTime end, CO2 outflux umol s, df .Date Date. df .DateTime start transform groupby df , Plant, Scenario, Sequence , DateTime start x 1 length x time numeric filter x x.DateTime start first date && x.DateTime end last date, df p data df mapping DateTime start Time \"Time\", CO2 outflux umol s, layout Date, color Plant string, group DateTime start Time \"Time\" mapping DateTime start Time, CO2 outflux umol s, layout Date string, color Plant string visual Scatter draw p, axis width 150, height 200 end save \".. 11 outputs CO2 fluxes 10min.png\", pCO2 all pH2O all let df dropmissing db 10min, DateTime end, transpiration diff g s, Sequence, transform groupby df , Plant, Scenario, Sequence , DateTime start x 1 length x time numeric filter x x.DateTime start first date && x.DateTime end last date, df p data df mapping DateTime start Time \"Time\", transpiration diff g s, color Sequence, row Scenario, col Plant string, group DateTime start Time \"Time\" visual Scatter draw p, axis width 150, height 200, xticks datetimeticks df .DateTime start, Dates.format. df .DateTime start, \"HH MM\" , facet linkxaxes none end open Bzip2CompressorStream, \"database 10min.csv.bz2\", \"w\" do stream CSV.write stream, db 10min end TableOfContents title \"üìö Table of Contents\", indent true, depth 4, aside true "},{"url":"basic_syntax/","title":"Basic Julia","tags":["welcome"],"text":" A Pluto.jl notebook v0.19.14 frontmatter title \"Basic Julia\" layout \"layout.jlhtml\" description \"\" tags \"welcome\" using Markdown using InteractiveUtils md\" Get started with Julia live Before being able to run this notebook successfully locally, you will need to set up Julia and Pluto. Spring21 installation \" md\" Variables We can define a variable using ` ` assignment . Then we can use its value in other expressions \" x 3 y 2x md\"By default Julia displays the output of the last operation. You can suppress the output by adding ` ` a semicolon at the end. \" md\"We can ask what type a variable has using `typeof` \" typeof y md\" Functions\" md\"We can use a short form, one line function definition for simple functions \" f x 2 x md\"Typing the function's name gives information about the function. To call it we must use parentheses \" f f 10 md\"For longer functions we use the following syntax with the `function` keyword and `end` \" function g x, y z x y return z^2 end g 1, 2 md\" For loops\" md\"Use `for` to loop through a pre determined set of values \" let s 0 for i in 1 10 s i Equivalent to s s i end s end md\"Here, `1 10` is a range representing the numbers from 1 to 10 \" typeof 1 10 md\"Above we used a `let` block to define a new local variable `s`. But blocks of code like this are usually better inside functions, so that they can be reused. For example, we could rewrite the above as follows \" function mysum n s 0 for i in 1 n s i end return s end mysum 100 md\" Conditionals `if`\" md\"We can evaluate whether a condition is true or not by simply writing the condition \" a 3 a 5 md\"We see that conditions have a Boolean `true` or `false` value. We can then use `if` to control what we do based on that value \" if a 5 \"small\" else \"big\" end md\"\"\"Note that the `if` also returns the last value that was evaluated, in this case the string `\"small\"` or `\"big\"`, Since Pluto is reactive, changing the definition of `a` above will automatically cause this to be reevaluated \"\"\" md\" Arrays\" md\" 1D arrays `Vector`s \" md\"We can make a `Vector` 1 dimensional, or 1D array using square brackets \" v 1, 2, 3 typeof v md\"The `1` in the type shows that this is a 1D array. We access elements also using square brackets \" v 2 v 2 10 md\"Note that Pluto does not automatically update cells when you modify elements of an array, but the value does change.\" md\"A nice way to create `Vector`s following a certain pattern is to use an array comprehension \" v2 i^2 for i in 1 10 md\" 2D arrays matrices \" md\"We can make small matrices 2D arrays with square brackets too \" M 1 2 3 4 typeof M md\"The `2` in the type confirms that this is a 2D array.\" md\"This won't work for larger matrices, though. For that we can use e.g.\" zeros 5, 5 md\"Note that `zeros` gives `Float64`s by default. We can also specify a type for the elements \" zeros Int, 4, 5 md\"We can then fill in the values we want by manipulating the elements, e.g. with a `for` loop.\" md\"A nice alternative syntax to create matrices following a certain pattern is an array comprehension with a double `for` loop \" i j for i in 1 5, j in 1 6 "},{"url":"cheatsheets/","title":"Cheatsheets","tags":["welcome"],"text":"Cheatsheets Getting Started with Julia - live . Fastrack to Julia  cheatsheet. MATLAB-Julia-Python comparative cheatsheet  by  QuantEcon group Plots.jl cheatsheet"},{"url":".","title":"Introduction","tags":["Homepage"],"text":""},{"url":"installation/","title":"Software installation","tags":["welcome"],"text":"First-time setup: Install Julia & Pluto Video version: Text and pictures version: Step 1: Install Julia  1.8.2 Go to  https://julialang.org/downloads  and download the current stable release, Julia  1.8.2 , using the correct version for your operating system (Linux x86, Mac, Windows, etc). Step 2: Run Julia After installing,  make sure that you can run Julia . On some systems, this means searching for the ‚ÄúJulia  1.8.2 ‚Äù program installed on your computer; in others, it means running the command  julia  in a terminal. Make sure that you can execute  1 + 1 : Make sure that you are able to launch Julia and calculate  1+1  before proceeding! Step 3: Install  Pluto Next we will install the  Pluto , the notebook environment that we will be using during the course. Pluto is a Julia  programming environment  designed for interactivity and quick experiments. Open the  Julia REPL . This is the command-line interface to Julia, similar to the previous screenshot. Here you type  Julia commands , and when you press ENTER, it runs, and you see the result. To install Pluto, we want to run a  package manager command . To switch from  Julia  mode to  Pkg  mode, type  ]  (closing square bracket) at the  julia>  prompt: \njulia> ]\n\n(@v 1.8 ) pkg>\n The line turns blue and the prompt changes to  pkg> , telling you that you are now in  package manager mode . This mode allows you to do operations on  packages  (also called libraries). To install Pluto, run the following (case sensitive) command to  add  (install) the package to your system by downloading it from the internet.\nYou should only need to do this  once  for each installation of Julia: \n(@v 1.8 ) pkg> add Pluto\n This might take a couple of minutes, so you can go get yourself a cup of tea! You can now close the terminal. Step 4: Use a modern browser: Mozilla Firefox or Google Chrome We need a modern browser to view Pluto notebooks with. Firefox and Chrome work best. Second time:  Running Pluto & opening a notebook Repeat the following steps whenever you want to work on a project or homework assignment. Step 1: Start Pluto Start the Julia REPL, like you did during the setup. In the REPL, type: julia> using Pluto\n\njulia> Pluto.run()\n The terminal tells us to go to  http://localhost:1234/  (or a similar URL). Let‚Äôs open Firefox or Chrome and type that into the address bar. If you‚Äôre curious about what a  Pluto notebook  looks like, have a look at the  Featured Notebooks . These notebooks are useful for learning some basics of Julia programming. If you want to hear the story behind Pluto, have a look a the  JuliaCon presentation . If nothing happens in the browser the first time, close Julia and try again. And please let us know! Step 2a: Opening a notebook from the web This is the main menu - here you can create new notebooks, or open existing ones. Our homework assignments will always be based on a  template notebook , available in this GitHub repository. To start from a template notebook on the web, you can  paste the URL into the blue box  and press ENTER. For example, homework 0 is available  here . Go to this page, and on the top right, click on the button that says ‚ÄúEdit or run this notebook‚Äù. From these instructions, copy the notebook link, and paste it into the box. Press ENTER, and select OK in the confirmation box. The first thing we will want to do is to save the notebook somewhere on our own computer; see below. Step 2b: Opening an existing notebook file When you launch Pluto for the second time, your recent notebooks will appear in the main menu. You can click on them to continue where you left off. If you want to run a local notebook file that you have not opened before, then you need to enter its  full path  into the blue box in the main menu. More on finding full paths in step 3. Step 3: Saving a notebook We first need a folder to save our homework in. Open your file explorer and create one. Next, we need to know the  absolute path  of that folder. Here‚Äôs how you do that in  Windows ,  MacOS  and  Ubuntu . For example, you might have: C:\\Users\\fons\\Documents\\18S191_assignments\\  on Windows /Users/fons/Documents/18S191_assignments/  on MacOS /home/fons/Documents/18S191_assignments/  on Ubuntu Now that we know the absolute path, go back to your Pluto notebook, and at the top of the page, click on  ‚ÄúSave notebook‚Ä¶‚Äù . This is where you type the  new path+filename for your notebook : Click  Choose . Step 4: Sharing a notebook After working on your notebook (your code is autosaved when you run it), you will find your notebook file in the folder we created in step 3. This the file that you can share with others, or submit as your homework assignment to Canvas. \nconst run = f => f();\nrun(async () => {\nconst versions = await (await fetch(`https://julialang-s3.julialang.org/bin/versions.json`)).json()\nconst version_names = Object.keys(versions).sort().reverse()\nconst stable = version_names.find(v => versions[v].stable)\nconsole.log({stable})\nconst pkg_stable = /\\d+\\.\\d+/.exec(stable)[0]\ndocument.querySelectorAll(\"auto-julia-version\").forEach(el => {\n    console.log(el)\n    el.innerText = el.getAttribute(\"short\") == null ? stable : pkg_stable\n})\n});"},{"url":"search/","title":"Search results","tags":[],"text":"window.init_search(); Search Results \nLoading..."},{"url":"sidebar data/","title":"sidebar data","tags":[],"text":"Dict main \"homepage\" collections \"homepage\" .pages, \"welcome\" collections \"welcome\" .pages, \"Climate\" collections \"climate\" .pages, \"Time synchronization\" collections \"timesync\" .pages, \"CO2 fluxes\" collections \"co2\" .pages, \"Thermal camera\" collections \"thermal\" .pages, \"Transpiration\" collections \"transpiration\" .pages, \"Photosynthesis and stomates\" collections \"walz\" .pages, \"SPAD\" collections \"spad\" .pages, \"Database\" collections \"database\" .pages, , about Dict authors name \"Rapha√´l P√©rez et al.\", url \"https github.com PalmStudio Biophysics database palm\" , , title \"A Comprehensive Database of Leaf Temperature, Water, and CO2 Fluxes\", subtitle \"in Young Oil Palm Plants Across Diverse Climate Scenarios for the Evaluation of Functional Structural Models\", term \"July 2024\", institution \"CIRAD\", institution url \"http www.cirad.fr\", institution logo \"palmstudio.png\", institution logo darkmode \"palmstudio.png\" "}]